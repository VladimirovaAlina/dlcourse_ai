{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"../assignment1/data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  3. ]\n",
      " [0.  2.  0.1]]\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00545136  0.0091191   0.00248885 -0.00247717]\n",
      " [-0.00390727 -0.00257593  0.00102213  0.00233768]]\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 49.127265, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.132965, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.135701, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.141594, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.137297, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.143605, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.140015, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.136999, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.141495, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.137662, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.132884, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.129482, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.132678, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.138517, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.130158, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.141367, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.138911, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.137569, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.136935, Train accuracy: 0.185556, val accuracy: 0.204000\n",
      "Loss: 49.126945, Train accuracy: 0.185556, val accuracy: 0.204000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12774eb50>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
