{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 889.274017\n",
      "Epoch 1, loss: 839.208329\n",
      "Epoch 2, loss: 872.373188\n",
      "Epoch 3, loss: 898.266490\n",
      "Epoch 4, loss: 884.930384\n",
      "Epoch 5, loss: 862.024798\n",
      "Epoch 6, loss: 888.933789\n",
      "Epoch 7, loss: 887.310190\n",
      "Epoch 8, loss: 889.419000\n",
      "Epoch 9, loss: 896.543694\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28d30cd30>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.119\n",
      "Epoch 0, loss: 860.231620\n",
      "Epoch 1, loss: 872.629516\n",
      "Epoch 2, loss: 944.369217\n",
      "Epoch 3, loss: 928.613256\n",
      "Epoch 4, loss: 928.083193\n",
      "Epoch 5, loss: 862.700603\n",
      "Epoch 6, loss: 875.927968\n",
      "Epoch 7, loss: 849.292254\n",
      "Epoch 8, loss: 936.459951\n",
      "Epoch 9, loss: 872.207162\n",
      "Epoch 10, loss: 971.715846\n",
      "Epoch 11, loss: 865.144833\n",
      "Epoch 12, loss: 891.365896\n",
      "Epoch 13, loss: 914.253366\n",
      "Epoch 14, loss: 911.579314\n",
      "Epoch 15, loss: 897.449050\n",
      "Epoch 16, loss: 874.425368\n",
      "Epoch 17, loss: 885.479268\n",
      "Epoch 18, loss: 890.961471\n",
      "Epoch 19, loss: 845.775171\n",
      "Epoch 20, loss: 899.770460\n",
      "Epoch 21, loss: 890.016157\n",
      "Epoch 22, loss: 904.505870\n",
      "Epoch 23, loss: 876.203235\n",
      "Epoch 24, loss: 874.826374\n",
      "Epoch 25, loss: 893.728744\n",
      "Epoch 26, loss: 879.486742\n",
      "Epoch 27, loss: 870.729546\n",
      "Epoch 28, loss: 921.109170\n",
      "Epoch 29, loss: 872.984400\n",
      "Epoch 30, loss: 912.569731\n",
      "Epoch 31, loss: 892.173938\n",
      "Epoch 32, loss: 874.168139\n",
      "Epoch 33, loss: 931.225568\n",
      "Epoch 34, loss: 867.614786\n",
      "Epoch 35, loss: 906.098919\n",
      "Epoch 36, loss: 907.791651\n",
      "Epoch 37, loss: 880.386052\n",
      "Epoch 38, loss: 956.177938\n",
      "Epoch 39, loss: 847.794620\n",
      "Epoch 40, loss: 881.460361\n",
      "Epoch 41, loss: 926.434202\n",
      "Epoch 42, loss: 882.670631\n",
      "Epoch 43, loss: 854.237375\n",
      "Epoch 44, loss: 886.276789\n",
      "Epoch 45, loss: 845.537764\n",
      "Epoch 46, loss: 896.416348\n",
      "Epoch 47, loss: 843.569688\n",
      "Epoch 48, loss: 872.582262\n",
      "Epoch 49, loss: 924.321675\n",
      "Epoch 50, loss: 896.083670\n",
      "Epoch 51, loss: 922.848027\n",
      "Epoch 52, loss: 844.107332\n",
      "Epoch 53, loss: 859.402505\n",
      "Epoch 54, loss: 850.167266\n",
      "Epoch 55, loss: 919.331353\n",
      "Epoch 56, loss: 920.148271\n",
      "Epoch 57, loss: 862.038657\n",
      "Epoch 58, loss: 907.721502\n",
      "Epoch 59, loss: 875.921427\n",
      "Epoch 60, loss: 857.157584\n",
      "Epoch 61, loss: 860.466453\n",
      "Epoch 62, loss: 888.692649\n",
      "Epoch 63, loss: 894.464056\n",
      "Epoch 64, loss: 881.396083\n",
      "Epoch 65, loss: 883.164353\n",
      "Epoch 66, loss: 883.956343\n",
      "Epoch 67, loss: 899.296845\n",
      "Epoch 68, loss: 875.833859\n",
      "Epoch 69, loss: 937.501597\n",
      "Epoch 70, loss: 932.309883\n",
      "Epoch 71, loss: 902.077430\n",
      "Epoch 72, loss: 860.170187\n",
      "Epoch 73, loss: 929.395942\n",
      "Epoch 74, loss: 914.892800\n",
      "Epoch 75, loss: 882.129325\n",
      "Epoch 76, loss: 902.943360\n",
      "Epoch 77, loss: 862.296117\n",
      "Epoch 78, loss: 875.406456\n",
      "Epoch 79, loss: 905.551791\n",
      "Epoch 80, loss: 908.296624\n",
      "Epoch 81, loss: 858.665230\n",
      "Epoch 82, loss: 899.613446\n",
      "Epoch 83, loss: 843.943294\n",
      "Epoch 84, loss: 846.891562\n",
      "Epoch 85, loss: 922.507816\n",
      "Epoch 86, loss: 919.802420\n",
      "Epoch 87, loss: 878.932452\n",
      "Epoch 88, loss: 865.449612\n",
      "Epoch 89, loss: 892.557725\n",
      "Epoch 90, loss: 885.152876\n",
      "Epoch 91, loss: 847.206475\n",
      "Epoch 92, loss: 839.816966\n",
      "Epoch 93, loss: 946.568404\n",
      "Epoch 94, loss: 872.787651\n",
      "Epoch 95, loss: 873.231763\n",
      "Epoch 96, loss: 924.912296\n",
      "Epoch 97, loss: 850.713400\n",
      "Epoch 98, loss: 890.141855\n",
      "Epoch 99, loss: 851.478705\n",
      "Accuracy after training for 100 epochs:  0.162\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 869.111095\n",
      "Epoch 1, loss: 881.311443\n",
      "Epoch 2, loss: 903.744005\n",
      "Epoch 3, loss: 867.411886\n",
      "Epoch 4, loss: 903.419754\n",
      "Epoch 5, loss: 868.703286\n",
      "Epoch 6, loss: 860.336827\n",
      "Epoch 7, loss: 858.845284\n",
      "Epoch 8, loss: 835.955158\n",
      "Epoch 9, loss: 813.709409\n",
      "Epoch 10, loss: 836.227541\n",
      "Epoch 11, loss: 838.611334\n",
      "Epoch 12, loss: 828.200931\n",
      "Epoch 13, loss: 808.805802\n",
      "Epoch 14, loss: 835.181772\n",
      "Epoch 15, loss: 778.618252\n",
      "Epoch 16, loss: 832.434855\n",
      "Epoch 17, loss: 756.732420\n",
      "Epoch 18, loss: 826.696970\n",
      "Epoch 19, loss: 772.822917\n",
      "Epoch 20, loss: 877.648863\n",
      "Epoch 21, loss: 846.734744\n",
      "Epoch 22, loss: 750.470539\n",
      "Epoch 23, loss: 801.858998\n",
      "Epoch 24, loss: 780.759125\n",
      "Epoch 25, loss: 839.672902\n",
      "Epoch 26, loss: 768.206604\n",
      "Epoch 27, loss: 821.287823\n",
      "Epoch 28, loss: 783.193696\n",
      "Epoch 29, loss: 864.829075\n",
      "Epoch 30, loss: 797.391198\n",
      "Epoch 31, loss: 785.296789\n",
      "Epoch 32, loss: 747.941397\n",
      "Epoch 33, loss: 797.895580\n",
      "Epoch 34, loss: 764.803142\n",
      "Epoch 35, loss: 855.817764\n",
      "Epoch 36, loss: 775.433801\n",
      "Epoch 37, loss: 812.548315\n",
      "Epoch 38, loss: 773.277365\n",
      "Epoch 39, loss: 781.987427\n",
      "Epoch 40, loss: 777.274477\n",
      "Epoch 41, loss: 762.244302\n",
      "Epoch 42, loss: 794.445954\n",
      "Epoch 43, loss: 810.269734\n",
      "Epoch 44, loss: 774.763072\n",
      "Epoch 45, loss: 772.544154\n",
      "Epoch 46, loss: 763.989569\n",
      "Epoch 47, loss: 783.922191\n",
      "Epoch 48, loss: 782.659707\n",
      "Epoch 49, loss: 770.546862\n",
      "Epoch 50, loss: 739.404909\n",
      "Epoch 51, loss: 795.299453\n",
      "Epoch 52, loss: 760.378440\n",
      "Epoch 53, loss: 808.179028\n",
      "Epoch 54, loss: 793.020883\n",
      "Epoch 55, loss: 771.403000\n",
      "Epoch 56, loss: 776.175626\n",
      "Epoch 57, loss: 750.660564\n",
      "Epoch 58, loss: 780.293314\n",
      "Epoch 59, loss: 780.459627\n",
      "Epoch 60, loss: 792.932711\n",
      "Epoch 61, loss: 788.025418\n",
      "Epoch 62, loss: 754.788776\n",
      "Epoch 63, loss: 733.393781\n",
      "Epoch 64, loss: 818.967952\n",
      "Epoch 65, loss: 762.414097\n",
      "Epoch 66, loss: 758.488464\n",
      "Epoch 67, loss: 790.425998\n",
      "Epoch 68, loss: 790.411150\n",
      "Epoch 69, loss: 747.627910\n",
      "Epoch 70, loss: 754.641596\n",
      "Epoch 71, loss: 754.268779\n",
      "Epoch 72, loss: 814.669139\n",
      "Epoch 73, loss: 781.697068\n",
      "Epoch 74, loss: 775.789108\n",
      "Epoch 75, loss: 778.115761\n",
      "Epoch 76, loss: 781.905965\n",
      "Epoch 77, loss: 759.881823\n",
      "Epoch 78, loss: 779.527176\n",
      "Epoch 79, loss: 793.773705\n",
      "Epoch 80, loss: 764.393602\n",
      "Epoch 81, loss: 758.353342\n",
      "Epoch 82, loss: 761.614872\n",
      "Epoch 83, loss: 768.026654\n",
      "Epoch 84, loss: 786.157080\n",
      "Epoch 85, loss: 784.313385\n",
      "Epoch 86, loss: 783.895815\n",
      "Epoch 87, loss: 765.255455\n",
      "Epoch 88, loss: 775.117577\n",
      "Epoch 89, loss: 755.990191\n",
      "Epoch 90, loss: 770.285244\n",
      "Epoch 91, loss: 777.404399\n",
      "Epoch 92, loss: 741.387218\n",
      "Epoch 93, loss: 800.899639\n",
      "Epoch 94, loss: 786.308412\n",
      "Epoch 95, loss: 791.694720\n",
      "Epoch 96, loss: 748.762337\n",
      "Epoch 97, loss: 810.984831\n",
      "Epoch 98, loss: 718.685990\n",
      "Epoch 99, loss: 746.595498\n",
      "Epoch 100, loss: 798.866147\n",
      "Epoch 101, loss: 721.188382\n",
      "Epoch 102, loss: 750.695547\n",
      "Epoch 103, loss: 782.936593\n",
      "Epoch 104, loss: 761.931919\n",
      "Epoch 105, loss: 772.117434\n",
      "Epoch 106, loss: 735.413539\n",
      "Epoch 107, loss: 767.965983\n",
      "Epoch 108, loss: 717.574262\n",
      "Epoch 109, loss: 801.730491\n",
      "Epoch 110, loss: 737.121347\n",
      "Epoch 111, loss: 767.409311\n",
      "Epoch 112, loss: 754.458796\n",
      "Epoch 113, loss: 726.673411\n",
      "Epoch 114, loss: 748.948717\n",
      "Epoch 115, loss: 750.940854\n",
      "Epoch 116, loss: 743.952750\n",
      "Epoch 117, loss: 775.781430\n",
      "Epoch 118, loss: 736.657977\n",
      "Epoch 119, loss: 756.702494\n",
      "Epoch 120, loss: 732.793710\n",
      "Epoch 121, loss: 777.485481\n",
      "Epoch 122, loss: 781.291879\n",
      "Epoch 123, loss: 737.921733\n",
      "Epoch 124, loss: 798.262316\n",
      "Epoch 125, loss: 751.020322\n",
      "Epoch 126, loss: 729.597542\n",
      "Epoch 127, loss: 781.166393\n",
      "Epoch 128, loss: 730.656459\n",
      "Epoch 129, loss: 796.150306\n",
      "Epoch 130, loss: 718.723676\n",
      "Epoch 131, loss: 772.776921\n",
      "Epoch 132, loss: 767.323734\n",
      "Epoch 133, loss: 759.714198\n",
      "Epoch 134, loss: 808.538924\n",
      "Epoch 135, loss: 697.842189\n",
      "Epoch 136, loss: 710.178417\n",
      "Epoch 137, loss: 778.163027\n",
      "Epoch 138, loss: 772.266863\n",
      "Epoch 139, loss: 728.262125\n",
      "Epoch 140, loss: 741.978194\n",
      "Epoch 141, loss: 751.256626\n",
      "Epoch 142, loss: 772.469778\n",
      "Epoch 143, loss: 735.917036\n",
      "Epoch 144, loss: 736.067170\n",
      "Epoch 145, loss: 761.347294\n",
      "Epoch 146, loss: 736.012277\n",
      "Epoch 147, loss: 765.014098\n",
      "Epoch 148, loss: 749.242374\n",
      "Epoch 149, loss: 768.314144\n",
      "Epoch 150, loss: 736.661278\n",
      "Epoch 151, loss: 787.985575\n",
      "Epoch 152, loss: 732.044031\n",
      "Epoch 153, loss: 757.539520\n",
      "Epoch 154, loss: 758.764997\n",
      "Epoch 155, loss: 670.918717\n",
      "Epoch 156, loss: 787.875855\n",
      "Epoch 157, loss: 735.012508\n",
      "Epoch 158, loss: 769.941484\n",
      "Epoch 159, loss: 729.895138\n",
      "Epoch 160, loss: 745.287986\n",
      "Epoch 161, loss: 727.349280\n",
      "Epoch 162, loss: 791.329185\n",
      "Epoch 163, loss: 762.703558\n",
      "Epoch 164, loss: 752.873563\n",
      "Epoch 165, loss: 674.070747\n",
      "Epoch 166, loss: 703.231899\n",
      "Epoch 167, loss: 747.557845\n",
      "Epoch 168, loss: 758.423682\n",
      "Epoch 169, loss: 719.959259\n",
      "Epoch 170, loss: 768.522668\n",
      "Epoch 171, loss: 756.339567\n",
      "Epoch 172, loss: 767.696967\n",
      "Epoch 173, loss: 755.424098\n",
      "Epoch 174, loss: 734.426255\n",
      "Epoch 175, loss: 735.305791\n",
      "Epoch 176, loss: 761.668500\n",
      "Epoch 177, loss: 723.636395\n",
      "Epoch 178, loss: 743.000483\n",
      "Epoch 179, loss: 741.787789\n",
      "Epoch 180, loss: 753.187177\n",
      "Epoch 181, loss: 727.360833\n",
      "Epoch 182, loss: 728.494192\n",
      "Epoch 183, loss: 712.243067\n",
      "Epoch 184, loss: 758.753603\n",
      "Epoch 185, loss: 733.689975\n",
      "Epoch 186, loss: 745.004504\n",
      "Epoch 187, loss: 729.748974\n",
      "Epoch 188, loss: 749.108573\n",
      "Epoch 189, loss: 700.170511\n",
      "Epoch 190, loss: 730.809056\n",
      "Epoch 191, loss: 810.452349\n",
      "Epoch 192, loss: 705.343537\n",
      "Epoch 193, loss: 777.764989\n",
      "Epoch 194, loss: 724.757562\n",
      "Epoch 195, loss: 724.913309\n",
      "Epoch 196, loss: 736.091765\n",
      "Epoch 197, loss: 710.514622\n",
      "Epoch 198, loss: 734.893593\n",
      "Epoch 199, loss: 744.720534\n",
      "Epoch 0, loss: 868.412322\n",
      "Epoch 1, loss: 884.388055\n",
      "Epoch 2, loss: 856.802126\n",
      "Epoch 3, loss: 861.704464\n",
      "Epoch 4, loss: 882.951067\n",
      "Epoch 5, loss: 859.646212\n",
      "Epoch 6, loss: 819.134532\n",
      "Epoch 7, loss: 789.445880\n",
      "Epoch 8, loss: 909.136780\n",
      "Epoch 9, loss: 834.317938\n",
      "Epoch 10, loss: 828.467354\n",
      "Epoch 11, loss: 838.454280\n",
      "Epoch 12, loss: 786.553166\n",
      "Epoch 13, loss: 841.436827\n",
      "Epoch 14, loss: 807.392591\n",
      "Epoch 15, loss: 840.058510\n",
      "Epoch 16, loss: 771.749804\n",
      "Epoch 17, loss: 818.409862\n",
      "Epoch 18, loss: 804.423568\n",
      "Epoch 19, loss: 831.733558\n",
      "Epoch 20, loss: 813.631716\n",
      "Epoch 21, loss: 811.920704\n",
      "Epoch 22, loss: 826.811555\n",
      "Epoch 23, loss: 782.433696\n",
      "Epoch 24, loss: 819.971832\n",
      "Epoch 25, loss: 811.762245\n",
      "Epoch 26, loss: 816.319097\n",
      "Epoch 27, loss: 751.163695\n",
      "Epoch 28, loss: 810.760027\n",
      "Epoch 29, loss: 771.299616\n",
      "Epoch 30, loss: 867.827579\n",
      "Epoch 31, loss: 807.933294\n",
      "Epoch 32, loss: 820.099617\n",
      "Epoch 33, loss: 744.817892\n",
      "Epoch 34, loss: 788.047825\n",
      "Epoch 35, loss: 803.322043\n",
      "Epoch 36, loss: 797.703135\n",
      "Epoch 37, loss: 806.505396\n",
      "Epoch 38, loss: 817.034451\n",
      "Epoch 39, loss: 812.330649\n",
      "Epoch 40, loss: 786.936131\n",
      "Epoch 41, loss: 781.137964\n",
      "Epoch 42, loss: 771.474733\n",
      "Epoch 43, loss: 735.727488\n",
      "Epoch 44, loss: 809.658156\n",
      "Epoch 45, loss: 779.709124\n",
      "Epoch 46, loss: 838.989442\n",
      "Epoch 47, loss: 762.266566\n",
      "Epoch 48, loss: 773.829546\n",
      "Epoch 49, loss: 799.132427\n",
      "Epoch 50, loss: 766.778331\n",
      "Epoch 51, loss: 800.712255\n",
      "Epoch 52, loss: 735.391017\n",
      "Epoch 53, loss: 780.375076\n",
      "Epoch 54, loss: 796.855297\n",
      "Epoch 55, loss: 783.830282\n",
      "Epoch 56, loss: 798.870352\n",
      "Epoch 57, loss: 810.879540\n",
      "Epoch 58, loss: 771.710888\n",
      "Epoch 59, loss: 763.205673\n",
      "Epoch 60, loss: 769.975916\n",
      "Epoch 61, loss: 752.879224\n",
      "Epoch 62, loss: 742.606144\n",
      "Epoch 63, loss: 782.268378\n",
      "Epoch 64, loss: 795.323235\n",
      "Epoch 65, loss: 788.308757\n",
      "Epoch 66, loss: 779.184466\n",
      "Epoch 67, loss: 764.988071\n",
      "Epoch 68, loss: 769.143341\n",
      "Epoch 69, loss: 780.644821\n",
      "Epoch 70, loss: 748.913981\n",
      "Epoch 71, loss: 753.985615\n",
      "Epoch 72, loss: 804.508652\n",
      "Epoch 73, loss: 772.745403\n",
      "Epoch 74, loss: 784.672694\n",
      "Epoch 75, loss: 792.494091\n",
      "Epoch 76, loss: 755.414905\n",
      "Epoch 77, loss: 780.290586\n",
      "Epoch 78, loss: 799.771128\n",
      "Epoch 79, loss: 814.599732\n",
      "Epoch 80, loss: 765.333039\n",
      "Epoch 81, loss: 751.810135\n",
      "Epoch 82, loss: 775.278508\n",
      "Epoch 83, loss: 736.741847\n",
      "Epoch 84, loss: 803.934453\n",
      "Epoch 85, loss: 788.754265\n",
      "Epoch 86, loss: 731.261632\n",
      "Epoch 87, loss: 801.177002\n",
      "Epoch 88, loss: 757.060585\n",
      "Epoch 89, loss: 757.675972\n",
      "Epoch 90, loss: 788.912540\n",
      "Epoch 91, loss: 788.832883\n",
      "Epoch 92, loss: 721.542847\n",
      "Epoch 93, loss: 774.617233\n",
      "Epoch 94, loss: 785.824912\n",
      "Epoch 95, loss: 758.393866\n",
      "Epoch 96, loss: 728.762272\n",
      "Epoch 97, loss: 771.913956\n",
      "Epoch 98, loss: 770.158113\n",
      "Epoch 99, loss: 712.945929\n",
      "Epoch 100, loss: 819.057426\n",
      "Epoch 101, loss: 753.739486\n",
      "Epoch 102, loss: 785.901569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103, loss: 723.907547\n",
      "Epoch 104, loss: 764.732251\n",
      "Epoch 105, loss: 749.069071\n",
      "Epoch 106, loss: 739.433324\n",
      "Epoch 107, loss: 716.789828\n",
      "Epoch 108, loss: 781.883712\n",
      "Epoch 109, loss: 776.141813\n",
      "Epoch 110, loss: 776.601055\n",
      "Epoch 111, loss: 754.312582\n",
      "Epoch 112, loss: 772.216471\n",
      "Epoch 113, loss: 783.128594\n",
      "Epoch 114, loss: 754.751182\n",
      "Epoch 115, loss: 782.543371\n",
      "Epoch 116, loss: 759.548276\n",
      "Epoch 117, loss: 742.223284\n",
      "Epoch 118, loss: 709.921258\n",
      "Epoch 119, loss: 753.820689\n",
      "Epoch 120, loss: 772.893156\n",
      "Epoch 121, loss: 730.151482\n",
      "Epoch 122, loss: 780.622308\n",
      "Epoch 123, loss: 746.070269\n",
      "Epoch 124, loss: 724.660097\n",
      "Epoch 125, loss: 814.867520\n",
      "Epoch 126, loss: 726.267703\n",
      "Epoch 127, loss: 696.488852\n",
      "Epoch 128, loss: 786.716589\n",
      "Epoch 129, loss: 781.330622\n",
      "Epoch 130, loss: 769.150613\n",
      "Epoch 131, loss: 769.691963\n",
      "Epoch 132, loss: 740.521436\n",
      "Epoch 133, loss: 711.142558\n",
      "Epoch 134, loss: 765.724908\n",
      "Epoch 135, loss: 787.070160\n",
      "Epoch 136, loss: 709.727881\n",
      "Epoch 137, loss: 774.607001\n",
      "Epoch 138, loss: 712.245138\n",
      "Epoch 139, loss: 765.113430\n",
      "Epoch 140, loss: 724.727834\n",
      "Epoch 141, loss: 723.509302\n",
      "Epoch 142, loss: 768.636197\n",
      "Epoch 143, loss: 809.815571\n",
      "Epoch 144, loss: 741.888831\n",
      "Epoch 145, loss: 777.295473\n",
      "Epoch 146, loss: 740.961077\n",
      "Epoch 147, loss: 756.514118\n",
      "Epoch 148, loss: 736.786368\n",
      "Epoch 149, loss: 712.605739\n",
      "Epoch 150, loss: 762.830410\n",
      "Epoch 151, loss: 760.878044\n",
      "Epoch 152, loss: 734.459731\n",
      "Epoch 153, loss: 756.532417\n",
      "Epoch 154, loss: 781.684031\n",
      "Epoch 155, loss: 750.880019\n",
      "Epoch 156, loss: 732.461929\n",
      "Epoch 157, loss: 763.289938\n",
      "Epoch 158, loss: 744.685845\n",
      "Epoch 159, loss: 703.522286\n",
      "Epoch 160, loss: 748.997169\n",
      "Epoch 161, loss: 717.241569\n",
      "Epoch 162, loss: 734.730356\n",
      "Epoch 163, loss: 761.194385\n",
      "Epoch 164, loss: 743.316077\n",
      "Epoch 165, loss: 741.939663\n",
      "Epoch 166, loss: 739.436835\n",
      "Epoch 167, loss: 725.509518\n",
      "Epoch 168, loss: 727.342808\n",
      "Epoch 169, loss: 741.638638\n",
      "Epoch 170, loss: 766.829589\n",
      "Epoch 171, loss: 796.717988\n",
      "Epoch 172, loss: 771.344705\n",
      "Epoch 173, loss: 727.208028\n",
      "Epoch 174, loss: 751.281194\n",
      "Epoch 175, loss: 745.060336\n",
      "Epoch 176, loss: 693.769755\n",
      "Epoch 177, loss: 746.829839\n",
      "Epoch 178, loss: 686.129999\n",
      "Epoch 179, loss: 745.860992\n",
      "Epoch 180, loss: 760.445352\n",
      "Epoch 181, loss: 730.931474\n",
      "Epoch 182, loss: 739.948168\n",
      "Epoch 183, loss: 712.436945\n",
      "Epoch 184, loss: 761.708500\n",
      "Epoch 185, loss: 769.054558\n",
      "Epoch 186, loss: 723.898825\n",
      "Epoch 187, loss: 753.116089\n",
      "Epoch 188, loss: 746.717514\n",
      "Epoch 189, loss: 723.666568\n",
      "Epoch 190, loss: 821.592703\n",
      "Epoch 191, loss: 734.852082\n",
      "Epoch 192, loss: 749.813854\n",
      "Epoch 193, loss: 745.741676\n",
      "Epoch 194, loss: 700.819937\n",
      "Epoch 195, loss: 704.495610\n",
      "Epoch 196, loss: 772.040209\n",
      "Epoch 197, loss: 732.432423\n",
      "Epoch 198, loss: 738.735469\n",
      "Epoch 199, loss: 741.312123\n",
      "Epoch 0, loss: 847.471211\n",
      "Epoch 1, loss: 901.702130\n",
      "Epoch 2, loss: 839.993773\n",
      "Epoch 3, loss: 862.546394\n",
      "Epoch 4, loss: 836.459962\n",
      "Epoch 5, loss: 872.049743\n",
      "Epoch 6, loss: 828.496317\n",
      "Epoch 7, loss: 845.273435\n",
      "Epoch 8, loss: 853.868262\n",
      "Epoch 9, loss: 828.718001\n",
      "Epoch 10, loss: 862.042173\n",
      "Epoch 11, loss: 808.554354\n",
      "Epoch 12, loss: 842.581544\n",
      "Epoch 13, loss: 834.450021\n",
      "Epoch 14, loss: 844.082046\n",
      "Epoch 15, loss: 820.828834\n",
      "Epoch 16, loss: 807.402618\n",
      "Epoch 17, loss: 816.413433\n",
      "Epoch 18, loss: 849.202587\n",
      "Epoch 19, loss: 849.668462\n",
      "Epoch 20, loss: 809.121322\n",
      "Epoch 21, loss: 758.505386\n",
      "Epoch 22, loss: 801.096013\n",
      "Epoch 23, loss: 844.893455\n",
      "Epoch 24, loss: 844.247132\n",
      "Epoch 25, loss: 788.936272\n",
      "Epoch 26, loss: 809.238397\n",
      "Epoch 27, loss: 764.570664\n",
      "Epoch 28, loss: 776.998675\n",
      "Epoch 29, loss: 787.472780\n",
      "Epoch 30, loss: 821.340842\n",
      "Epoch 31, loss: 804.670450\n",
      "Epoch 32, loss: 805.948564\n",
      "Epoch 33, loss: 785.117940\n",
      "Epoch 34, loss: 832.261173\n",
      "Epoch 35, loss: 755.794451\n",
      "Epoch 36, loss: 824.517688\n",
      "Epoch 37, loss: 748.813339\n",
      "Epoch 38, loss: 760.981685\n",
      "Epoch 39, loss: 783.089987\n",
      "Epoch 40, loss: 792.763480\n",
      "Epoch 41, loss: 804.731615\n",
      "Epoch 42, loss: 822.698399\n",
      "Epoch 43, loss: 818.119014\n",
      "Epoch 44, loss: 764.337058\n",
      "Epoch 45, loss: 801.595756\n",
      "Epoch 46, loss: 774.356156\n",
      "Epoch 47, loss: 789.437583\n",
      "Epoch 48, loss: 783.701678\n",
      "Epoch 49, loss: 826.769797\n",
      "Epoch 50, loss: 802.491332\n",
      "Epoch 51, loss: 725.904137\n",
      "Epoch 52, loss: 797.392528\n",
      "Epoch 53, loss: 783.079807\n",
      "Epoch 54, loss: 741.301587\n",
      "Epoch 55, loss: 786.820703\n",
      "Epoch 56, loss: 783.360749\n",
      "Epoch 57, loss: 785.270411\n",
      "Epoch 58, loss: 786.600397\n",
      "Epoch 59, loss: 778.320702\n",
      "Epoch 60, loss: 801.343947\n",
      "Epoch 61, loss: 770.579692\n",
      "Epoch 62, loss: 768.744903\n",
      "Epoch 63, loss: 788.329179\n",
      "Epoch 64, loss: 807.772040\n",
      "Epoch 65, loss: 692.912462\n",
      "Epoch 66, loss: 806.932408\n",
      "Epoch 67, loss: 756.847142\n",
      "Epoch 68, loss: 776.970107\n",
      "Epoch 69, loss: 773.326630\n",
      "Epoch 70, loss: 807.504353\n",
      "Epoch 71, loss: 738.055958\n",
      "Epoch 72, loss: 819.509498\n",
      "Epoch 73, loss: 735.255612\n",
      "Epoch 74, loss: 770.519436\n",
      "Epoch 75, loss: 778.877191\n",
      "Epoch 76, loss: 722.822594\n",
      "Epoch 77, loss: 811.966135\n",
      "Epoch 78, loss: 786.131107\n",
      "Epoch 79, loss: 752.233930\n",
      "Epoch 80, loss: 776.077413\n",
      "Epoch 81, loss: 786.018397\n",
      "Epoch 82, loss: 769.852319\n",
      "Epoch 83, loss: 741.898394\n",
      "Epoch 84, loss: 749.159915\n",
      "Epoch 85, loss: 715.022978\n",
      "Epoch 86, loss: 792.651399\n",
      "Epoch 87, loss: 758.947654\n",
      "Epoch 88, loss: 761.579291\n",
      "Epoch 89, loss: 737.926914\n",
      "Epoch 90, loss: 772.106862\n",
      "Epoch 91, loss: 761.305485\n",
      "Epoch 92, loss: 764.884929\n",
      "Epoch 93, loss: 799.950584\n",
      "Epoch 94, loss: 743.144702\n",
      "Epoch 95, loss: 782.387020\n",
      "Epoch 96, loss: 717.542199\n",
      "Epoch 97, loss: 802.378039\n",
      "Epoch 98, loss: 730.965266\n",
      "Epoch 99, loss: 740.605951\n",
      "Epoch 100, loss: 792.108293\n",
      "Epoch 101, loss: 709.862417\n",
      "Epoch 102, loss: 797.236263\n",
      "Epoch 103, loss: 775.655450\n",
      "Epoch 104, loss: 754.880756\n",
      "Epoch 105, loss: 750.841810\n",
      "Epoch 106, loss: 776.016084\n",
      "Epoch 107, loss: 745.282626\n",
      "Epoch 108, loss: 765.213039\n",
      "Epoch 109, loss: 727.954544\n",
      "Epoch 110, loss: 800.577653\n",
      "Epoch 111, loss: 764.783194\n",
      "Epoch 112, loss: 745.454713\n",
      "Epoch 113, loss: 753.740534\n",
      "Epoch 114, loss: 759.498075\n",
      "Epoch 115, loss: 736.226915\n",
      "Epoch 116, loss: 756.389926\n",
      "Epoch 117, loss: 774.000756\n",
      "Epoch 118, loss: 756.134966\n",
      "Epoch 119, loss: 761.472990\n",
      "Epoch 120, loss: 761.451179\n",
      "Epoch 121, loss: 729.856553\n",
      "Epoch 122, loss: 766.391332\n",
      "Epoch 123, loss: 746.055340\n",
      "Epoch 124, loss: 763.319203\n",
      "Epoch 125, loss: 751.159382\n",
      "Epoch 126, loss: 754.835415\n",
      "Epoch 127, loss: 702.676673\n",
      "Epoch 128, loss: 721.233434\n",
      "Epoch 129, loss: 754.046246\n",
      "Epoch 130, loss: 745.312808\n",
      "Epoch 131, loss: 770.803556\n",
      "Epoch 132, loss: 741.649013\n",
      "Epoch 133, loss: 770.327362\n",
      "Epoch 134, loss: 776.294178\n",
      "Epoch 135, loss: 711.582223\n",
      "Epoch 136, loss: 779.317866\n",
      "Epoch 137, loss: 767.647239\n",
      "Epoch 138, loss: 719.037964\n",
      "Epoch 139, loss: 778.797952\n",
      "Epoch 140, loss: 729.066136\n",
      "Epoch 141, loss: 786.786542\n",
      "Epoch 142, loss: 755.779750\n",
      "Epoch 143, loss: 754.278170\n",
      "Epoch 144, loss: 721.322476\n",
      "Epoch 145, loss: 761.650003\n",
      "Epoch 146, loss: 770.620648\n",
      "Epoch 147, loss: 738.829314\n",
      "Epoch 148, loss: 728.761769\n",
      "Epoch 149, loss: 727.038554\n",
      "Epoch 150, loss: 703.967913\n",
      "Epoch 151, loss: 731.311132\n",
      "Epoch 152, loss: 771.838443\n",
      "Epoch 153, loss: 747.141366\n",
      "Epoch 154, loss: 724.326014\n",
      "Epoch 155, loss: 735.032160\n",
      "Epoch 156, loss: 753.541242\n",
      "Epoch 157, loss: 707.817981\n",
      "Epoch 158, loss: 772.280681\n",
      "Epoch 159, loss: 768.651046\n",
      "Epoch 160, loss: 734.674458\n",
      "Epoch 161, loss: 720.007913\n",
      "Epoch 162, loss: 778.844934\n",
      "Epoch 163, loss: 756.042740\n",
      "Epoch 164, loss: 742.560685\n",
      "Epoch 165, loss: 709.103999\n",
      "Epoch 166, loss: 726.840724\n",
      "Epoch 167, loss: 757.197476\n",
      "Epoch 168, loss: 706.572177\n",
      "Epoch 169, loss: 719.544754\n",
      "Epoch 170, loss: 763.451358\n",
      "Epoch 171, loss: 712.596371\n",
      "Epoch 172, loss: 743.792103\n",
      "Epoch 173, loss: 759.239681\n",
      "Epoch 174, loss: 729.402157\n",
      "Epoch 175, loss: 791.808427\n",
      "Epoch 176, loss: 723.843014\n",
      "Epoch 177, loss: 763.543704\n",
      "Epoch 178, loss: 718.988649\n",
      "Epoch 179, loss: 729.399787\n",
      "Epoch 180, loss: 755.653188\n",
      "Epoch 181, loss: 797.112695\n",
      "Epoch 182, loss: 701.921068\n",
      "Epoch 183, loss: 724.939400\n",
      "Epoch 184, loss: 720.949937\n",
      "Epoch 185, loss: 786.210312\n",
      "Epoch 186, loss: 754.946321\n",
      "Epoch 187, loss: 750.859212\n",
      "Epoch 188, loss: 759.728446\n",
      "Epoch 189, loss: 767.784237\n",
      "Epoch 190, loss: 735.218369\n",
      "Epoch 191, loss: 739.849532\n",
      "Epoch 192, loss: 753.921423\n",
      "Epoch 193, loss: 702.259348\n",
      "Epoch 194, loss: 740.958095\n",
      "Epoch 195, loss: 732.154372\n",
      "Epoch 196, loss: 754.001486\n",
      "Epoch 197, loss: 694.097500\n",
      "Epoch 198, loss: 754.757177\n",
      "Epoch 199, loss: 713.591217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 688.426939\n",
      "Epoch 1, loss: 681.672791\n",
      "Epoch 2, loss: 676.443817\n",
      "Epoch 3, loss: 671.980765\n",
      "Epoch 4, loss: 668.108539\n",
      "Epoch 5, loss: 664.957837\n",
      "Epoch 6, loss: 662.335250\n",
      "Epoch 7, loss: 659.965865\n",
      "Epoch 8, loss: 658.165328\n",
      "Epoch 9, loss: 656.113344\n",
      "Epoch 10, loss: 654.489283\n",
      "Epoch 11, loss: 653.166241\n",
      "Epoch 12, loss: 652.039782\n",
      "Epoch 13, loss: 650.857914\n",
      "Epoch 14, loss: 649.732087\n",
      "Epoch 15, loss: 648.840662\n",
      "Epoch 16, loss: 648.119682\n",
      "Epoch 17, loss: 647.128002\n",
      "Epoch 18, loss: 646.412563\n",
      "Epoch 19, loss: 645.623568\n",
      "Epoch 20, loss: 645.069642\n",
      "Epoch 21, loss: 644.514588\n",
      "Epoch 22, loss: 644.134856\n",
      "Epoch 23, loss: 643.497190\n",
      "Epoch 24, loss: 642.879228\n",
      "Epoch 25, loss: 642.358572\n",
      "Epoch 26, loss: 641.947528\n",
      "Epoch 27, loss: 641.532923\n",
      "Epoch 28, loss: 641.021065\n",
      "Epoch 29, loss: 640.710997\n",
      "Epoch 30, loss: 640.193429\n",
      "Epoch 31, loss: 639.631230\n",
      "Epoch 32, loss: 639.350874\n",
      "Epoch 33, loss: 638.886647\n",
      "Epoch 34, loss: 638.614397\n",
      "Epoch 35, loss: 638.441030\n",
      "Epoch 36, loss: 637.962186\n",
      "Epoch 37, loss: 637.565899\n",
      "Epoch 38, loss: 637.377787\n",
      "Epoch 39, loss: 637.049878\n",
      "Epoch 40, loss: 636.658508\n",
      "Epoch 41, loss: 636.329544\n",
      "Epoch 42, loss: 636.250007\n",
      "Epoch 43, loss: 635.724838\n",
      "Epoch 44, loss: 635.681024\n",
      "Epoch 45, loss: 635.295292\n",
      "Epoch 46, loss: 634.953240\n",
      "Epoch 47, loss: 634.767398\n",
      "Epoch 48, loss: 634.534634\n",
      "Epoch 49, loss: 634.347601\n",
      "Epoch 50, loss: 633.940230\n",
      "Epoch 51, loss: 633.662230\n",
      "Epoch 52, loss: 633.635989\n",
      "Epoch 53, loss: 633.435314\n",
      "Epoch 54, loss: 633.089224\n",
      "Epoch 55, loss: 632.985258\n",
      "Epoch 56, loss: 632.907427\n",
      "Epoch 57, loss: 632.528733\n",
      "Epoch 58, loss: 632.152993\n",
      "Epoch 59, loss: 632.337167\n",
      "Epoch 60, loss: 631.812386\n",
      "Epoch 61, loss: 631.758651\n",
      "Epoch 62, loss: 631.454297\n",
      "Epoch 63, loss: 631.514233\n",
      "Epoch 64, loss: 631.205497\n",
      "Epoch 65, loss: 631.048118\n",
      "Epoch 66, loss: 630.802779\n",
      "Epoch 67, loss: 630.722970\n",
      "Epoch 68, loss: 630.480799\n",
      "Epoch 69, loss: 630.258274\n",
      "Epoch 70, loss: 630.237298\n",
      "Epoch 71, loss: 629.973983\n",
      "Epoch 72, loss: 629.707214\n",
      "Epoch 73, loss: 629.546766\n",
      "Epoch 74, loss: 629.480154\n",
      "Epoch 75, loss: 629.337555\n",
      "Epoch 76, loss: 629.142241\n",
      "Epoch 77, loss: 628.972226\n",
      "Epoch 78, loss: 628.665789\n",
      "Epoch 79, loss: 628.645007\n",
      "Epoch 80, loss: 628.566658\n",
      "Epoch 81, loss: 628.545226\n",
      "Epoch 82, loss: 628.361445\n",
      "Epoch 83, loss: 628.098029\n",
      "Epoch 84, loss: 627.998628\n",
      "Epoch 85, loss: 627.812592\n",
      "Epoch 86, loss: 627.735024\n",
      "Epoch 87, loss: 627.396173\n",
      "Epoch 88, loss: 627.377624\n",
      "Epoch 89, loss: 627.284062\n",
      "Epoch 90, loss: 627.111828\n",
      "Epoch 91, loss: 627.303218\n",
      "Epoch 92, loss: 626.840159\n",
      "Epoch 93, loss: 627.032916\n",
      "Epoch 94, loss: 626.613229\n",
      "Epoch 95, loss: 626.483316\n",
      "Epoch 96, loss: 626.469938\n",
      "Epoch 97, loss: 626.324628\n",
      "Epoch 98, loss: 626.099879\n",
      "Epoch 99, loss: 626.022579\n",
      "Epoch 100, loss: 626.071835\n",
      "Epoch 101, loss: 625.834649\n",
      "Epoch 102, loss: 625.655944\n",
      "Epoch 103, loss: 625.642616\n",
      "Epoch 104, loss: 625.696671\n",
      "Epoch 105, loss: 625.326535\n",
      "Epoch 106, loss: 625.224598\n",
      "Epoch 107, loss: 625.046741\n",
      "Epoch 108, loss: 624.969585\n",
      "Epoch 109, loss: 624.759316\n",
      "Epoch 110, loss: 624.844858\n",
      "Epoch 111, loss: 624.701050\n",
      "Epoch 112, loss: 624.411880\n",
      "Epoch 113, loss: 624.322205\n",
      "Epoch 114, loss: 624.396351\n",
      "Epoch 115, loss: 624.288798\n",
      "Epoch 116, loss: 624.174903\n",
      "Epoch 117, loss: 623.955284\n",
      "Epoch 118, loss: 623.913239\n",
      "Epoch 119, loss: 623.741305\n",
      "Epoch 120, loss: 623.781122\n",
      "Epoch 121, loss: 623.674818\n",
      "Epoch 122, loss: 623.354746\n",
      "Epoch 123, loss: 623.377818\n",
      "Epoch 124, loss: 623.332294\n",
      "Epoch 125, loss: 623.133496\n",
      "Epoch 126, loss: 623.275829\n",
      "Epoch 127, loss: 622.900916\n",
      "Epoch 128, loss: 622.725023\n",
      "Epoch 129, loss: 622.821915\n",
      "Epoch 130, loss: 622.714357\n",
      "Epoch 131, loss: 622.856537\n",
      "Epoch 132, loss: 622.616604\n",
      "Epoch 133, loss: 622.314065\n",
      "Epoch 134, loss: 622.450710\n",
      "Epoch 135, loss: 622.328783\n",
      "Epoch 136, loss: 622.139651\n",
      "Epoch 137, loss: 621.934387\n",
      "Epoch 138, loss: 622.021137\n",
      "Epoch 139, loss: 621.890237\n",
      "Epoch 140, loss: 621.783639\n",
      "Epoch 141, loss: 621.744602\n",
      "Epoch 142, loss: 621.541879\n",
      "Epoch 143, loss: 621.482839\n",
      "Epoch 144, loss: 621.552752\n",
      "Epoch 145, loss: 621.362959\n",
      "Epoch 146, loss: 621.406822\n",
      "Epoch 147, loss: 621.018674\n",
      "Epoch 148, loss: 621.158659\n",
      "Epoch 149, loss: 620.982021\n",
      "Epoch 150, loss: 620.858928\n",
      "Epoch 151, loss: 620.672929\n",
      "Epoch 152, loss: 620.801040\n",
      "Epoch 153, loss: 620.828229\n",
      "Epoch 154, loss: 620.700975\n",
      "Epoch 155, loss: 620.468856\n",
      "Epoch 156, loss: 620.584381\n",
      "Epoch 157, loss: 620.194887\n",
      "Epoch 158, loss: 620.424340\n",
      "Epoch 159, loss: 620.226346\n",
      "Epoch 160, loss: 620.092125\n",
      "Epoch 161, loss: 620.038435\n",
      "Epoch 162, loss: 620.060089\n",
      "Epoch 163, loss: 620.041063\n",
      "Epoch 164, loss: 619.706173\n",
      "Epoch 165, loss: 619.760868\n",
      "Epoch 166, loss: 619.528733\n",
      "Epoch 167, loss: 619.612165\n",
      "Epoch 168, loss: 619.519991\n",
      "Epoch 169, loss: 619.546327\n",
      "Epoch 170, loss: 619.390526\n",
      "Epoch 171, loss: 619.371255\n",
      "Epoch 172, loss: 619.008507\n",
      "Epoch 173, loss: 619.209972\n",
      "Epoch 174, loss: 619.164962\n",
      "Epoch 175, loss: 618.857483\n",
      "Epoch 176, loss: 618.921535\n",
      "Epoch 177, loss: 618.862519\n",
      "Epoch 178, loss: 618.713717\n",
      "Epoch 179, loss: 618.784916\n",
      "Epoch 180, loss: 618.607802\n",
      "Epoch 181, loss: 618.572413\n",
      "Epoch 182, loss: 618.415853\n",
      "Epoch 183, loss: 618.403920\n",
      "Epoch 184, loss: 618.240748\n",
      "Epoch 185, loss: 618.212046\n",
      "Epoch 186, loss: 618.168702\n",
      "Epoch 187, loss: 618.047127\n",
      "Epoch 188, loss: 617.927153\n",
      "Epoch 189, loss: 617.923101\n",
      "Epoch 190, loss: 617.939491\n",
      "Epoch 191, loss: 617.711043\n",
      "Epoch 192, loss: 617.707309\n",
      "Epoch 193, loss: 617.742053\n",
      "Epoch 194, loss: 617.520245\n",
      "Epoch 195, loss: 617.515921\n",
      "Epoch 196, loss: 617.582582\n",
      "Epoch 197, loss: 617.457995\n",
      "Epoch 198, loss: 617.197476\n",
      "Epoch 199, loss: 617.209363\n",
      "Epoch 0, loss: 688.138364\n",
      "Epoch 1, loss: 681.521305\n",
      "Epoch 2, loss: 676.314029\n",
      "Epoch 3, loss: 672.061309\n",
      "Epoch 4, loss: 668.236007\n",
      "Epoch 5, loss: 664.873679\n",
      "Epoch 6, loss: 662.199826\n",
      "Epoch 7, loss: 659.957149\n",
      "Epoch 8, loss: 657.851674\n",
      "Epoch 9, loss: 655.987428\n",
      "Epoch 10, loss: 654.741005\n",
      "Epoch 11, loss: 653.074559\n",
      "Epoch 12, loss: 651.849319\n",
      "Epoch 13, loss: 650.693081\n",
      "Epoch 14, loss: 649.682522\n",
      "Epoch 15, loss: 649.121062\n",
      "Epoch 16, loss: 647.944010\n",
      "Epoch 17, loss: 647.061384\n",
      "Epoch 18, loss: 646.367617\n",
      "Epoch 19, loss: 645.908307\n",
      "Epoch 20, loss: 645.050707\n",
      "Epoch 21, loss: 644.375441\n",
      "Epoch 22, loss: 643.866021\n",
      "Epoch 23, loss: 643.368536\n",
      "Epoch 24, loss: 642.818659\n",
      "Epoch 25, loss: 642.302412\n",
      "Epoch 26, loss: 641.883797\n",
      "Epoch 27, loss: 641.316846\n",
      "Epoch 28, loss: 641.089461\n",
      "Epoch 29, loss: 640.588508\n",
      "Epoch 30, loss: 639.914177\n",
      "Epoch 31, loss: 639.729324\n",
      "Epoch 32, loss: 639.342184\n",
      "Epoch 33, loss: 638.917698\n",
      "Epoch 34, loss: 638.444919\n",
      "Epoch 35, loss: 638.289418\n",
      "Epoch 36, loss: 638.001922\n",
      "Epoch 37, loss: 637.633318\n",
      "Epoch 38, loss: 637.407840\n",
      "Epoch 39, loss: 637.155125\n",
      "Epoch 40, loss: 636.866199\n",
      "Epoch 41, loss: 636.459394\n",
      "Epoch 42, loss: 636.241797\n",
      "Epoch 43, loss: 635.807217\n",
      "Epoch 44, loss: 635.490756\n",
      "Epoch 45, loss: 635.382390\n",
      "Epoch 46, loss: 635.073226\n",
      "Epoch 47, loss: 634.936916\n",
      "Epoch 48, loss: 634.524590\n",
      "Epoch 49, loss: 634.410740\n",
      "Epoch 50, loss: 633.981561\n",
      "Epoch 51, loss: 633.787817\n",
      "Epoch 52, loss: 633.601130\n",
      "Epoch 53, loss: 633.358995\n",
      "Epoch 54, loss: 633.359320\n",
      "Epoch 55, loss: 633.110639\n",
      "Epoch 56, loss: 632.665678\n",
      "Epoch 57, loss: 632.607503\n",
      "Epoch 58, loss: 632.134027\n",
      "Epoch 59, loss: 632.199436\n",
      "Epoch 60, loss: 631.841541\n",
      "Epoch 61, loss: 631.694888\n",
      "Epoch 62, loss: 631.541098\n",
      "Epoch 63, loss: 631.289701\n",
      "Epoch 64, loss: 631.140247\n",
      "Epoch 65, loss: 630.965980\n",
      "Epoch 66, loss: 630.696577\n",
      "Epoch 67, loss: 630.929754\n",
      "Epoch 68, loss: 630.373208\n",
      "Epoch 69, loss: 630.357890\n",
      "Epoch 70, loss: 630.182063\n",
      "Epoch 71, loss: 629.967484\n",
      "Epoch 72, loss: 629.768607\n",
      "Epoch 73, loss: 629.792372\n",
      "Epoch 74, loss: 629.280553\n",
      "Epoch 75, loss: 629.231257\n",
      "Epoch 76, loss: 628.995938\n",
      "Epoch 77, loss: 629.070245\n",
      "Epoch 78, loss: 628.727705\n",
      "Epoch 79, loss: 628.765211\n",
      "Epoch 80, loss: 628.589676\n",
      "Epoch 81, loss: 628.375144\n",
      "Epoch 82, loss: 628.170298\n",
      "Epoch 83, loss: 628.019885\n",
      "Epoch 84, loss: 627.774039\n",
      "Epoch 85, loss: 627.887570\n",
      "Epoch 86, loss: 627.485828\n",
      "Epoch 87, loss: 627.711269\n",
      "Epoch 88, loss: 627.354640\n",
      "Epoch 89, loss: 627.405752\n",
      "Epoch 90, loss: 627.131020\n",
      "Epoch 91, loss: 626.933853\n",
      "Epoch 92, loss: 627.009914\n",
      "Epoch 93, loss: 626.774040\n",
      "Epoch 94, loss: 626.668744\n",
      "Epoch 95, loss: 626.428789\n",
      "Epoch 96, loss: 626.416405\n",
      "Epoch 97, loss: 626.245901\n",
      "Epoch 98, loss: 626.262050\n",
      "Epoch 99, loss: 625.932323\n",
      "Epoch 100, loss: 626.199229\n",
      "Epoch 101, loss: 625.764971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102, loss: 625.542879\n",
      "Epoch 103, loss: 625.614616\n",
      "Epoch 104, loss: 625.583141\n",
      "Epoch 105, loss: 625.534215\n",
      "Epoch 106, loss: 625.334265\n",
      "Epoch 107, loss: 625.017908\n",
      "Epoch 108, loss: 624.979606\n",
      "Epoch 109, loss: 624.882894\n",
      "Epoch 110, loss: 625.129307\n",
      "Epoch 111, loss: 624.814706\n",
      "Epoch 112, loss: 624.483266\n",
      "Epoch 113, loss: 624.413363\n",
      "Epoch 114, loss: 624.447626\n",
      "Epoch 115, loss: 624.175190\n",
      "Epoch 116, loss: 623.956658\n",
      "Epoch 117, loss: 623.987048\n",
      "Epoch 118, loss: 623.897435\n",
      "Epoch 119, loss: 623.851325\n",
      "Epoch 120, loss: 623.706296\n",
      "Epoch 121, loss: 623.574213\n",
      "Epoch 122, loss: 623.516406\n",
      "Epoch 123, loss: 623.272541\n",
      "Epoch 124, loss: 623.184350\n",
      "Epoch 125, loss: 623.214411\n",
      "Epoch 126, loss: 623.242610\n",
      "Epoch 127, loss: 623.074062\n",
      "Epoch 128, loss: 623.032320\n",
      "Epoch 129, loss: 622.943211\n",
      "Epoch 130, loss: 622.564217\n",
      "Epoch 131, loss: 622.654209\n",
      "Epoch 132, loss: 622.369665\n",
      "Epoch 133, loss: 622.501127\n",
      "Epoch 134, loss: 622.299662\n",
      "Epoch 135, loss: 622.331948\n",
      "Epoch 136, loss: 622.137639\n",
      "Epoch 137, loss: 621.830015\n",
      "Epoch 138, loss: 621.840710\n",
      "Epoch 139, loss: 621.842819\n",
      "Epoch 140, loss: 621.753695\n",
      "Epoch 141, loss: 621.847248\n",
      "Epoch 142, loss: 621.449805\n",
      "Epoch 143, loss: 621.503686\n",
      "Epoch 144, loss: 621.451763\n",
      "Epoch 145, loss: 621.547836\n",
      "Epoch 146, loss: 621.229452\n",
      "Epoch 147, loss: 620.984707\n",
      "Epoch 148, loss: 621.215408\n",
      "Epoch 149, loss: 621.080123\n",
      "Epoch 150, loss: 620.751355\n",
      "Epoch 151, loss: 620.826803\n",
      "Epoch 152, loss: 620.848957\n",
      "Epoch 153, loss: 620.699471\n",
      "Epoch 154, loss: 620.546350\n",
      "Epoch 155, loss: 620.513311\n",
      "Epoch 156, loss: 620.440287\n",
      "Epoch 157, loss: 620.428718\n",
      "Epoch 158, loss: 620.429545\n",
      "Epoch 159, loss: 620.103437\n",
      "Epoch 160, loss: 620.334688\n",
      "Epoch 161, loss: 619.937610\n",
      "Epoch 162, loss: 620.004348\n",
      "Epoch 163, loss: 619.933693\n",
      "Epoch 164, loss: 619.656189\n",
      "Epoch 165, loss: 619.711199\n",
      "Epoch 166, loss: 619.789969\n",
      "Epoch 167, loss: 619.453945\n",
      "Epoch 168, loss: 619.310270\n",
      "Epoch 169, loss: 619.409319\n",
      "Epoch 170, loss: 619.347810\n",
      "Epoch 171, loss: 619.122338\n",
      "Epoch 172, loss: 619.159763\n",
      "Epoch 173, loss: 619.055168\n",
      "Epoch 174, loss: 619.058943\n",
      "Epoch 175, loss: 619.204915\n",
      "Epoch 176, loss: 618.923853\n",
      "Epoch 177, loss: 618.750936\n",
      "Epoch 178, loss: 618.671373\n",
      "Epoch 179, loss: 618.725971\n",
      "Epoch 180, loss: 618.716985\n",
      "Epoch 181, loss: 618.554871\n",
      "Epoch 182, loss: 618.486194\n",
      "Epoch 183, loss: 618.355658\n",
      "Epoch 184, loss: 618.266855\n",
      "Epoch 185, loss: 618.382458\n",
      "Epoch 186, loss: 618.180820\n",
      "Epoch 187, loss: 618.200098\n",
      "Epoch 188, loss: 617.915939\n",
      "Epoch 189, loss: 617.813491\n",
      "Epoch 190, loss: 617.800148\n",
      "Epoch 191, loss: 617.695974\n",
      "Epoch 192, loss: 617.686443\n",
      "Epoch 193, loss: 617.842508\n",
      "Epoch 194, loss: 617.707275\n",
      "Epoch 195, loss: 617.567223\n",
      "Epoch 196, loss: 617.367048\n",
      "Epoch 197, loss: 617.326733\n",
      "Epoch 198, loss: 617.179736\n",
      "Epoch 199, loss: 617.119595\n",
      "Epoch 0, loss: 688.117693\n",
      "Epoch 1, loss: 681.523541\n",
      "Epoch 2, loss: 676.469547\n",
      "Epoch 3, loss: 671.902063\n",
      "Epoch 4, loss: 668.063129\n",
      "Epoch 5, loss: 665.096829\n",
      "Epoch 6, loss: 662.135514\n",
      "Epoch 7, loss: 659.836147\n",
      "Epoch 8, loss: 657.931807\n",
      "Epoch 9, loss: 656.221721\n",
      "Epoch 10, loss: 654.710185\n",
      "Epoch 11, loss: 653.157933\n",
      "Epoch 12, loss: 651.943999\n",
      "Epoch 13, loss: 651.165826\n",
      "Epoch 14, loss: 649.841842\n",
      "Epoch 15, loss: 648.712236\n",
      "Epoch 16, loss: 648.047833\n",
      "Epoch 17, loss: 647.300932\n",
      "Epoch 18, loss: 646.295959\n",
      "Epoch 19, loss: 645.679650\n",
      "Epoch 20, loss: 645.270335\n",
      "Epoch 21, loss: 644.619208\n",
      "Epoch 22, loss: 643.790951\n",
      "Epoch 23, loss: 643.374493\n",
      "Epoch 24, loss: 642.865751\n",
      "Epoch 25, loss: 642.415872\n",
      "Epoch 26, loss: 641.994961\n",
      "Epoch 27, loss: 641.362404\n",
      "Epoch 28, loss: 640.992456\n",
      "Epoch 29, loss: 640.520153\n",
      "Epoch 30, loss: 640.199653\n",
      "Epoch 31, loss: 639.344272\n",
      "Epoch 32, loss: 639.445121\n",
      "Epoch 33, loss: 639.040383\n",
      "Epoch 34, loss: 638.510105\n",
      "Epoch 35, loss: 638.215551\n",
      "Epoch 36, loss: 637.907262\n",
      "Epoch 37, loss: 637.725663\n",
      "Epoch 38, loss: 637.370766\n",
      "Epoch 39, loss: 637.001505\n",
      "Epoch 40, loss: 636.671292\n",
      "Epoch 41, loss: 636.358043\n",
      "Epoch 42, loss: 636.439064\n",
      "Epoch 43, loss: 635.721314\n",
      "Epoch 44, loss: 635.554681\n",
      "Epoch 45, loss: 635.250334\n",
      "Epoch 46, loss: 635.033075\n",
      "Epoch 47, loss: 634.743869\n",
      "Epoch 48, loss: 634.591720\n",
      "Epoch 49, loss: 634.381525\n",
      "Epoch 50, loss: 634.003456\n",
      "Epoch 51, loss: 633.987121\n",
      "Epoch 52, loss: 633.833584\n",
      "Epoch 53, loss: 633.363794\n",
      "Epoch 54, loss: 633.246237\n",
      "Epoch 55, loss: 632.950712\n",
      "Epoch 56, loss: 632.831077\n",
      "Epoch 57, loss: 632.647936\n",
      "Epoch 58, loss: 632.352314\n",
      "Epoch 59, loss: 632.231167\n",
      "Epoch 60, loss: 632.113175\n",
      "Epoch 61, loss: 631.869608\n",
      "Epoch 62, loss: 631.601536\n",
      "Epoch 63, loss: 631.176807\n",
      "Epoch 64, loss: 631.184133\n",
      "Epoch 65, loss: 631.129326\n",
      "Epoch 66, loss: 630.756828\n",
      "Epoch 67, loss: 630.552788\n",
      "Epoch 68, loss: 630.479554\n",
      "Epoch 69, loss: 630.384543\n",
      "Epoch 70, loss: 630.129960\n",
      "Epoch 71, loss: 629.724085\n",
      "Epoch 72, loss: 629.795813\n",
      "Epoch 73, loss: 629.624923\n",
      "Epoch 74, loss: 629.393164\n",
      "Epoch 75, loss: 629.185140\n",
      "Epoch 76, loss: 629.135817\n",
      "Epoch 77, loss: 628.873375\n",
      "Epoch 78, loss: 628.808376\n",
      "Epoch 79, loss: 628.639103\n",
      "Epoch 80, loss: 628.526988\n",
      "Epoch 81, loss: 628.420394\n",
      "Epoch 82, loss: 628.217106\n",
      "Epoch 83, loss: 627.918476\n",
      "Epoch 84, loss: 627.883782\n",
      "Epoch 85, loss: 627.934384\n",
      "Epoch 86, loss: 627.703376\n",
      "Epoch 87, loss: 627.697636\n",
      "Epoch 88, loss: 627.475700\n",
      "Epoch 89, loss: 627.254462\n",
      "Epoch 90, loss: 627.055860\n",
      "Epoch 91, loss: 627.173038\n",
      "Epoch 92, loss: 626.827837\n",
      "Epoch 93, loss: 626.766158\n",
      "Epoch 94, loss: 626.730026\n",
      "Epoch 95, loss: 626.633935\n",
      "Epoch 96, loss: 626.375527\n",
      "Epoch 97, loss: 626.440069\n",
      "Epoch 98, loss: 626.006482\n",
      "Epoch 99, loss: 625.897576\n",
      "Epoch 100, loss: 625.946623\n",
      "Epoch 101, loss: 625.718115\n",
      "Epoch 102, loss: 625.740616\n",
      "Epoch 103, loss: 625.384139\n",
      "Epoch 104, loss: 625.422853\n",
      "Epoch 105, loss: 625.098969\n",
      "Epoch 106, loss: 625.290202\n",
      "Epoch 107, loss: 625.123528\n",
      "Epoch 108, loss: 624.881083\n",
      "Epoch 109, loss: 624.788005\n",
      "Epoch 110, loss: 624.706344\n",
      "Epoch 111, loss: 624.774515\n",
      "Epoch 112, loss: 624.426960\n",
      "Epoch 113, loss: 624.631492\n",
      "Epoch 114, loss: 624.485789\n",
      "Epoch 115, loss: 624.303623\n",
      "Epoch 116, loss: 624.199295\n",
      "Epoch 117, loss: 624.131767\n",
      "Epoch 118, loss: 623.948937\n",
      "Epoch 119, loss: 623.681405\n",
      "Epoch 120, loss: 623.714566\n",
      "Epoch 121, loss: 623.595078\n",
      "Epoch 122, loss: 623.633988\n",
      "Epoch 123, loss: 623.430969\n",
      "Epoch 124, loss: 623.179742\n",
      "Epoch 125, loss: 623.162693\n",
      "Epoch 126, loss: 623.170822\n",
      "Epoch 127, loss: 622.941290\n",
      "Epoch 128, loss: 622.861058\n",
      "Epoch 129, loss: 622.685900\n",
      "Epoch 130, loss: 622.607957\n",
      "Epoch 131, loss: 622.594275\n",
      "Epoch 132, loss: 622.612986\n",
      "Epoch 133, loss: 622.540514\n",
      "Epoch 134, loss: 622.341925\n",
      "Epoch 135, loss: 622.295804\n",
      "Epoch 136, loss: 622.159049\n",
      "Epoch 137, loss: 622.066812\n",
      "Epoch 138, loss: 622.009348\n",
      "Epoch 139, loss: 621.882405\n",
      "Epoch 140, loss: 621.741319\n",
      "Epoch 141, loss: 621.734553\n",
      "Epoch 142, loss: 621.453526\n",
      "Epoch 143, loss: 621.382493\n",
      "Epoch 144, loss: 621.472774\n",
      "Epoch 145, loss: 621.263397\n",
      "Epoch 146, loss: 621.135425\n",
      "Epoch 147, loss: 621.046498\n",
      "Epoch 148, loss: 621.059531\n",
      "Epoch 149, loss: 620.958200\n",
      "Epoch 150, loss: 621.081996\n",
      "Epoch 151, loss: 620.757336\n",
      "Epoch 152, loss: 620.627523\n",
      "Epoch 153, loss: 620.618727\n",
      "Epoch 154, loss: 620.615027\n",
      "Epoch 155, loss: 620.423965\n",
      "Epoch 156, loss: 620.531382\n",
      "Epoch 157, loss: 620.414195\n",
      "Epoch 158, loss: 620.356652\n",
      "Epoch 159, loss: 620.438210\n",
      "Epoch 160, loss: 620.209309\n",
      "Epoch 161, loss: 620.179629\n",
      "Epoch 162, loss: 619.940442\n",
      "Epoch 163, loss: 620.024410\n",
      "Epoch 164, loss: 619.649748\n",
      "Epoch 165, loss: 619.807405\n",
      "Epoch 166, loss: 619.494538\n",
      "Epoch 167, loss: 619.398267\n",
      "Epoch 168, loss: 619.536422\n",
      "Epoch 169, loss: 619.371257\n",
      "Epoch 170, loss: 619.160377\n",
      "Epoch 171, loss: 619.286804\n",
      "Epoch 172, loss: 619.178642\n",
      "Epoch 173, loss: 619.020217\n",
      "Epoch 174, loss: 619.094531\n",
      "Epoch 175, loss: 619.112705\n",
      "Epoch 176, loss: 618.965359\n",
      "Epoch 177, loss: 618.615888\n",
      "Epoch 178, loss: 618.798026\n",
      "Epoch 179, loss: 618.590315\n",
      "Epoch 180, loss: 618.598327\n",
      "Epoch 181, loss: 618.566620\n",
      "Epoch 182, loss: 618.546625\n",
      "Epoch 183, loss: 618.518884\n",
      "Epoch 184, loss: 618.164753\n",
      "Epoch 185, loss: 618.296798\n",
      "Epoch 186, loss: 618.207047\n",
      "Epoch 187, loss: 618.221970\n",
      "Epoch 188, loss: 618.044239\n",
      "Epoch 189, loss: 618.248236\n",
      "Epoch 190, loss: 617.909608\n",
      "Epoch 191, loss: 617.860534\n",
      "Epoch 192, loss: 617.744298\n",
      "Epoch 193, loss: 617.425514\n",
      "Epoch 194, loss: 617.745752\n",
      "Epoch 195, loss: 617.664789\n",
      "Epoch 196, loss: 617.443727\n",
      "Epoch 197, loss: 617.359699\n",
      "Epoch 198, loss: 617.564241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199, loss: 617.508846\n",
      "Epoch 0, loss: 690.468225\n",
      "Epoch 1, loss: 689.588121\n",
      "Epoch 2, loss: 688.806702\n",
      "Epoch 3, loss: 688.026997\n",
      "Epoch 4, loss: 687.279499\n",
      "Epoch 5, loss: 686.551719\n",
      "Epoch 6, loss: 685.843980\n",
      "Epoch 7, loss: 685.147644\n",
      "Epoch 8, loss: 684.485397\n",
      "Epoch 9, loss: 683.815077\n",
      "Epoch 10, loss: 683.175236\n",
      "Epoch 11, loss: 682.539026\n",
      "Epoch 12, loss: 681.918893\n",
      "Epoch 13, loss: 681.308701\n",
      "Epoch 14, loss: 680.703523\n",
      "Epoch 15, loss: 680.133386\n",
      "Epoch 16, loss: 679.547944\n",
      "Epoch 17, loss: 678.992874\n",
      "Epoch 18, loss: 678.441965\n",
      "Epoch 19, loss: 677.913869\n",
      "Epoch 20, loss: 677.396251\n",
      "Epoch 21, loss: 676.845989\n",
      "Epoch 22, loss: 676.344849\n",
      "Epoch 23, loss: 675.826482\n",
      "Epoch 24, loss: 675.346075\n",
      "Epoch 25, loss: 674.869520\n",
      "Epoch 26, loss: 674.393816\n",
      "Epoch 27, loss: 673.924983\n",
      "Epoch 28, loss: 673.473359\n",
      "Epoch 29, loss: 673.014152\n",
      "Epoch 30, loss: 672.594304\n",
      "Epoch 31, loss: 672.151742\n",
      "Epoch 32, loss: 671.729844\n",
      "Epoch 33, loss: 671.297407\n",
      "Epoch 34, loss: 670.892326\n",
      "Epoch 35, loss: 670.482110\n",
      "Epoch 36, loss: 670.086784\n",
      "Epoch 37, loss: 669.699524\n",
      "Epoch 38, loss: 669.306664\n",
      "Epoch 39, loss: 668.933948\n",
      "Epoch 40, loss: 668.558773\n",
      "Epoch 41, loss: 668.203087\n",
      "Epoch 42, loss: 667.839082\n",
      "Epoch 43, loss: 667.470526\n",
      "Epoch 44, loss: 667.116376\n",
      "Epoch 45, loss: 666.783124\n",
      "Epoch 46, loss: 666.447762\n",
      "Epoch 47, loss: 666.123137\n",
      "Epoch 48, loss: 665.800391\n",
      "Epoch 49, loss: 665.457920\n",
      "Epoch 50, loss: 665.166807\n",
      "Epoch 51, loss: 664.827930\n",
      "Epoch 52, loss: 664.516676\n",
      "Epoch 53, loss: 664.221542\n",
      "Epoch 54, loss: 663.941970\n",
      "Epoch 55, loss: 663.642345\n",
      "Epoch 56, loss: 663.353967\n",
      "Epoch 57, loss: 663.074363\n",
      "Epoch 58, loss: 662.793818\n",
      "Epoch 59, loss: 662.508818\n",
      "Epoch 60, loss: 662.240089\n",
      "Epoch 61, loss: 661.978032\n",
      "Epoch 62, loss: 661.728431\n",
      "Epoch 63, loss: 661.457612\n",
      "Epoch 64, loss: 661.206018\n",
      "Epoch 65, loss: 660.957248\n",
      "Epoch 66, loss: 660.726764\n",
      "Epoch 67, loss: 660.465026\n",
      "Epoch 68, loss: 660.240185\n",
      "Epoch 69, loss: 660.002407\n",
      "Epoch 70, loss: 659.759150\n",
      "Epoch 71, loss: 659.541033\n",
      "Epoch 72, loss: 659.317742\n",
      "Epoch 73, loss: 659.091073\n",
      "Epoch 74, loss: 658.865234\n",
      "Epoch 75, loss: 658.647158\n",
      "Epoch 76, loss: 658.445215\n",
      "Epoch 77, loss: 658.214142\n",
      "Epoch 78, loss: 658.029201\n",
      "Epoch 79, loss: 657.829642\n",
      "Epoch 80, loss: 657.614203\n",
      "Epoch 81, loss: 657.421673\n",
      "Epoch 82, loss: 657.221928\n",
      "Epoch 83, loss: 657.021501\n",
      "Epoch 84, loss: 656.834733\n",
      "Epoch 85, loss: 656.645266\n",
      "Epoch 86, loss: 656.453249\n",
      "Epoch 87, loss: 656.269885\n",
      "Epoch 88, loss: 656.103945\n",
      "Epoch 89, loss: 655.934689\n",
      "Epoch 90, loss: 655.748534\n",
      "Epoch 91, loss: 655.576357\n",
      "Epoch 92, loss: 655.410470\n",
      "Epoch 93, loss: 655.236719\n",
      "Epoch 94, loss: 655.077400\n",
      "Epoch 95, loss: 654.898338\n",
      "Epoch 96, loss: 654.739708\n",
      "Epoch 97, loss: 654.588097\n",
      "Epoch 98, loss: 654.417460\n",
      "Epoch 99, loss: 654.258820\n",
      "Epoch 100, loss: 654.094501\n",
      "Epoch 101, loss: 653.952004\n",
      "Epoch 102, loss: 653.799360\n",
      "Epoch 103, loss: 653.657349\n",
      "Epoch 104, loss: 653.504533\n",
      "Epoch 105, loss: 653.369575\n",
      "Epoch 106, loss: 653.204853\n",
      "Epoch 107, loss: 653.062483\n",
      "Epoch 108, loss: 652.940244\n",
      "Epoch 109, loss: 652.786637\n",
      "Epoch 110, loss: 652.650621\n",
      "Epoch 111, loss: 652.533027\n",
      "Epoch 112, loss: 652.378947\n",
      "Epoch 113, loss: 652.236618\n",
      "Epoch 114, loss: 652.131529\n",
      "Epoch 115, loss: 651.989538\n",
      "Epoch 116, loss: 651.854317\n",
      "Epoch 117, loss: 651.728338\n",
      "Epoch 118, loss: 651.603134\n",
      "Epoch 119, loss: 651.482551\n",
      "Epoch 120, loss: 651.373259\n",
      "Epoch 121, loss: 651.230430\n",
      "Epoch 122, loss: 651.125251\n",
      "Epoch 123, loss: 651.005683\n",
      "Epoch 124, loss: 650.878022\n",
      "Epoch 125, loss: 650.754628\n",
      "Epoch 126, loss: 650.647490\n",
      "Epoch 127, loss: 650.536786\n",
      "Epoch 128, loss: 650.431471\n",
      "Epoch 129, loss: 650.298300\n",
      "Epoch 130, loss: 650.196320\n",
      "Epoch 131, loss: 650.091243\n",
      "Epoch 132, loss: 649.977148\n",
      "Epoch 133, loss: 649.871095\n",
      "Epoch 134, loss: 649.762594\n",
      "Epoch 135, loss: 649.640577\n",
      "Epoch 136, loss: 649.553952\n",
      "Epoch 137, loss: 649.448460\n",
      "Epoch 138, loss: 649.341163\n",
      "Epoch 139, loss: 649.237791\n",
      "Epoch 140, loss: 649.151590\n",
      "Epoch 141, loss: 649.038635\n",
      "Epoch 142, loss: 648.935434\n",
      "Epoch 143, loss: 648.842302\n",
      "Epoch 144, loss: 648.735822\n",
      "Epoch 145, loss: 648.650699\n",
      "Epoch 146, loss: 648.551005\n",
      "Epoch 147, loss: 648.458191\n",
      "Epoch 148, loss: 648.371018\n",
      "Epoch 149, loss: 648.270150\n",
      "Epoch 150, loss: 648.168769\n",
      "Epoch 151, loss: 648.083568\n",
      "Epoch 152, loss: 647.995048\n",
      "Epoch 153, loss: 647.904346\n",
      "Epoch 154, loss: 647.800613\n",
      "Epoch 155, loss: 647.717943\n",
      "Epoch 156, loss: 647.623240\n",
      "Epoch 157, loss: 647.540663\n",
      "Epoch 158, loss: 647.451902\n",
      "Epoch 159, loss: 647.365995\n",
      "Epoch 160, loss: 647.290688\n",
      "Epoch 161, loss: 647.192948\n",
      "Epoch 162, loss: 647.105467\n",
      "Epoch 163, loss: 647.037881\n",
      "Epoch 164, loss: 646.933295\n",
      "Epoch 165, loss: 646.873462\n",
      "Epoch 166, loss: 646.786166\n",
      "Epoch 167, loss: 646.699493\n",
      "Epoch 168, loss: 646.614185\n",
      "Epoch 169, loss: 646.531798\n",
      "Epoch 170, loss: 646.479070\n",
      "Epoch 171, loss: 646.377780\n",
      "Epoch 172, loss: 646.309015\n",
      "Epoch 173, loss: 646.240038\n",
      "Epoch 174, loss: 646.141479\n",
      "Epoch 175, loss: 646.081248\n",
      "Epoch 176, loss: 646.018603\n",
      "Epoch 177, loss: 645.925466\n",
      "Epoch 178, loss: 645.843860\n",
      "Epoch 179, loss: 645.776435\n",
      "Epoch 180, loss: 645.696755\n",
      "Epoch 181, loss: 645.642475\n",
      "Epoch 182, loss: 645.579257\n",
      "Epoch 183, loss: 645.477118\n",
      "Epoch 184, loss: 645.414411\n",
      "Epoch 185, loss: 645.338666\n",
      "Epoch 186, loss: 645.274530\n",
      "Epoch 187, loss: 645.198069\n",
      "Epoch 188, loss: 645.129501\n",
      "Epoch 189, loss: 645.063454\n",
      "Epoch 190, loss: 645.000668\n",
      "Epoch 191, loss: 644.911091\n",
      "Epoch 192, loss: 644.840894\n",
      "Epoch 193, loss: 644.784493\n",
      "Epoch 194, loss: 644.702947\n",
      "Epoch 195, loss: 644.651940\n",
      "Epoch 196, loss: 644.585937\n",
      "Epoch 197, loss: 644.516682\n",
      "Epoch 198, loss: 644.453833\n",
      "Epoch 199, loss: 644.382455\n",
      "Epoch 0, loss: 690.479580\n",
      "Epoch 1, loss: 689.617084\n",
      "Epoch 2, loss: 688.790450\n",
      "Epoch 3, loss: 688.036451\n",
      "Epoch 4, loss: 687.290249\n",
      "Epoch 5, loss: 686.547708\n",
      "Epoch 6, loss: 685.844494\n",
      "Epoch 7, loss: 685.144899\n",
      "Epoch 8, loss: 684.484220\n",
      "Epoch 9, loss: 683.810600\n",
      "Epoch 10, loss: 683.176771\n",
      "Epoch 11, loss: 682.538375\n",
      "Epoch 12, loss: 681.921279\n",
      "Epoch 13, loss: 681.297490\n",
      "Epoch 14, loss: 680.697650\n",
      "Epoch 15, loss: 680.123535\n",
      "Epoch 16, loss: 679.565167\n",
      "Epoch 17, loss: 678.987350\n",
      "Epoch 18, loss: 678.449270\n",
      "Epoch 19, loss: 677.898765\n",
      "Epoch 20, loss: 677.384771\n",
      "Epoch 21, loss: 676.855675\n",
      "Epoch 22, loss: 676.344301\n",
      "Epoch 23, loss: 675.846660\n",
      "Epoch 24, loss: 675.356132\n",
      "Epoch 25, loss: 674.870438\n",
      "Epoch 26, loss: 674.408176\n",
      "Epoch 27, loss: 673.936551\n",
      "Epoch 28, loss: 673.483260\n",
      "Epoch 29, loss: 673.009288\n",
      "Epoch 30, loss: 672.570043\n",
      "Epoch 31, loss: 672.117564\n",
      "Epoch 32, loss: 671.726458\n",
      "Epoch 33, loss: 671.301581\n",
      "Epoch 34, loss: 670.891474\n",
      "Epoch 35, loss: 670.477056\n",
      "Epoch 36, loss: 670.076961\n",
      "Epoch 37, loss: 669.693938\n",
      "Epoch 38, loss: 669.308574\n",
      "Epoch 39, loss: 668.918533\n",
      "Epoch 40, loss: 668.550163\n",
      "Epoch 41, loss: 668.178918\n",
      "Epoch 42, loss: 667.821672\n",
      "Epoch 43, loss: 667.465118\n",
      "Epoch 44, loss: 667.135867\n",
      "Epoch 45, loss: 666.776119\n",
      "Epoch 46, loss: 666.447684\n",
      "Epoch 47, loss: 666.103079\n",
      "Epoch 48, loss: 665.777756\n",
      "Epoch 49, loss: 665.460625\n",
      "Epoch 50, loss: 665.147564\n",
      "Epoch 51, loss: 664.837026\n",
      "Epoch 52, loss: 664.521445\n",
      "Epoch 53, loss: 664.229505\n",
      "Epoch 54, loss: 663.928563\n",
      "Epoch 55, loss: 663.647449\n",
      "Epoch 56, loss: 663.354015\n",
      "Epoch 57, loss: 663.061265\n",
      "Epoch 58, loss: 662.787226\n",
      "Epoch 59, loss: 662.506697\n",
      "Epoch 60, loss: 662.228751\n",
      "Epoch 61, loss: 661.977077\n",
      "Epoch 62, loss: 661.702636\n",
      "Epoch 63, loss: 661.471355\n",
      "Epoch 64, loss: 661.203774\n",
      "Epoch 65, loss: 660.956574\n",
      "Epoch 66, loss: 660.703019\n",
      "Epoch 67, loss: 660.459342\n",
      "Epoch 68, loss: 660.217846\n",
      "Epoch 69, loss: 659.998115\n",
      "Epoch 70, loss: 659.752856\n",
      "Epoch 71, loss: 659.541309\n",
      "Epoch 72, loss: 659.301435\n",
      "Epoch 73, loss: 659.085855\n",
      "Epoch 74, loss: 658.864967\n",
      "Epoch 75, loss: 658.631192\n",
      "Epoch 76, loss: 658.445442\n",
      "Epoch 77, loss: 658.216410\n",
      "Epoch 78, loss: 658.007305\n",
      "Epoch 79, loss: 657.825081\n",
      "Epoch 80, loss: 657.605119\n",
      "Epoch 81, loss: 657.412614\n",
      "Epoch 82, loss: 657.223517\n",
      "Epoch 83, loss: 657.035919\n",
      "Epoch 84, loss: 656.826353\n",
      "Epoch 85, loss: 656.644379\n",
      "Epoch 86, loss: 656.467105\n",
      "Epoch 87, loss: 656.274693\n",
      "Epoch 88, loss: 656.090826\n",
      "Epoch 89, loss: 655.916154\n",
      "Epoch 90, loss: 655.753482\n",
      "Epoch 91, loss: 655.560237\n",
      "Epoch 92, loss: 655.391925\n",
      "Epoch 93, loss: 655.227367\n",
      "Epoch 94, loss: 655.048720\n",
      "Epoch 95, loss: 654.904961\n",
      "Epoch 96, loss: 654.733874\n",
      "Epoch 97, loss: 654.567059\n",
      "Epoch 98, loss: 654.429698\n",
      "Epoch 99, loss: 654.251303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, loss: 654.105433\n",
      "Epoch 101, loss: 653.940855\n",
      "Epoch 102, loss: 653.786180\n",
      "Epoch 103, loss: 653.657544\n",
      "Epoch 104, loss: 653.488327\n",
      "Epoch 105, loss: 653.353957\n",
      "Epoch 106, loss: 653.218427\n",
      "Epoch 107, loss: 653.069371\n",
      "Epoch 108, loss: 652.939393\n",
      "Epoch 109, loss: 652.799917\n",
      "Epoch 110, loss: 652.656144\n",
      "Epoch 111, loss: 652.523176\n",
      "Epoch 112, loss: 652.383183\n",
      "Epoch 113, loss: 652.242765\n",
      "Epoch 114, loss: 652.109112\n",
      "Epoch 115, loss: 651.984627\n",
      "Epoch 116, loss: 651.872542\n",
      "Epoch 117, loss: 651.732792\n",
      "Epoch 118, loss: 651.603624\n",
      "Epoch 119, loss: 651.476382\n",
      "Epoch 120, loss: 651.371063\n",
      "Epoch 121, loss: 651.240065\n",
      "Epoch 122, loss: 651.103054\n",
      "Epoch 123, loss: 650.995547\n",
      "Epoch 124, loss: 650.880670\n",
      "Epoch 125, loss: 650.751546\n",
      "Epoch 126, loss: 650.637660\n",
      "Epoch 127, loss: 650.523853\n",
      "Epoch 128, loss: 650.411874\n",
      "Epoch 129, loss: 650.323150\n",
      "Epoch 130, loss: 650.185312\n",
      "Epoch 131, loss: 650.078966\n",
      "Epoch 132, loss: 649.974909\n",
      "Epoch 133, loss: 649.873769\n",
      "Epoch 134, loss: 649.744391\n",
      "Epoch 135, loss: 649.647275\n",
      "Epoch 136, loss: 649.536710\n",
      "Epoch 137, loss: 649.443954\n",
      "Epoch 138, loss: 649.330588\n",
      "Epoch 139, loss: 649.231750\n",
      "Epoch 140, loss: 649.129416\n",
      "Epoch 141, loss: 649.017460\n",
      "Epoch 142, loss: 648.933132\n",
      "Epoch 143, loss: 648.821133\n",
      "Epoch 144, loss: 648.744601\n",
      "Epoch 145, loss: 648.647949\n",
      "Epoch 146, loss: 648.547149\n",
      "Epoch 147, loss: 648.458353\n",
      "Epoch 148, loss: 648.366196\n",
      "Epoch 149, loss: 648.262308\n",
      "Epoch 150, loss: 648.177481\n",
      "Epoch 151, loss: 648.077922\n",
      "Epoch 152, loss: 647.973196\n",
      "Epoch 153, loss: 647.893647\n",
      "Epoch 154, loss: 647.811072\n",
      "Epoch 155, loss: 647.717146\n",
      "Epoch 156, loss: 647.614590\n",
      "Epoch 157, loss: 647.543746\n",
      "Epoch 158, loss: 647.466748\n",
      "Epoch 159, loss: 647.371843\n",
      "Epoch 160, loss: 647.283702\n",
      "Epoch 161, loss: 647.190155\n",
      "Epoch 162, loss: 647.101185\n",
      "Epoch 163, loss: 647.027317\n",
      "Epoch 164, loss: 646.940874\n",
      "Epoch 165, loss: 646.868820\n",
      "Epoch 166, loss: 646.767191\n",
      "Epoch 167, loss: 646.705777\n",
      "Epoch 168, loss: 646.603094\n",
      "Epoch 169, loss: 646.542624\n",
      "Epoch 170, loss: 646.461003\n",
      "Epoch 171, loss: 646.388163\n",
      "Epoch 172, loss: 646.303639\n",
      "Epoch 173, loss: 646.217556\n",
      "Epoch 174, loss: 646.148709\n",
      "Epoch 175, loss: 646.069171\n",
      "Epoch 176, loss: 646.007022\n",
      "Epoch 177, loss: 645.925356\n",
      "Epoch 178, loss: 645.842646\n",
      "Epoch 179, loss: 645.779672\n",
      "Epoch 180, loss: 645.683322\n",
      "Epoch 181, loss: 645.643804\n",
      "Epoch 182, loss: 645.556873\n",
      "Epoch 183, loss: 645.473636\n",
      "Epoch 184, loss: 645.426294\n",
      "Epoch 185, loss: 645.338348\n",
      "Epoch 186, loss: 645.264068\n",
      "Epoch 187, loss: 645.196149\n",
      "Epoch 188, loss: 645.132856\n",
      "Epoch 189, loss: 645.049327\n",
      "Epoch 190, loss: 644.972384\n",
      "Epoch 191, loss: 644.924407\n",
      "Epoch 192, loss: 644.851740\n",
      "Epoch 193, loss: 644.771630\n",
      "Epoch 194, loss: 644.717623\n",
      "Epoch 195, loss: 644.639966\n",
      "Epoch 196, loss: 644.576644\n",
      "Epoch 197, loss: 644.524595\n",
      "Epoch 198, loss: 644.450475\n",
      "Epoch 199, loss: 644.377903\n",
      "Epoch 0, loss: 690.516160\n",
      "Epoch 1, loss: 689.656576\n",
      "Epoch 2, loss: 688.839253\n",
      "Epoch 3, loss: 688.086595\n",
      "Epoch 4, loss: 687.347338\n",
      "Epoch 5, loss: 686.611415\n",
      "Epoch 6, loss: 685.901555\n",
      "Epoch 7, loss: 685.209951\n",
      "Epoch 8, loss: 684.508491\n",
      "Epoch 9, loss: 683.855890\n",
      "Epoch 10, loss: 683.200256\n",
      "Epoch 11, loss: 682.589462\n",
      "Epoch 12, loss: 681.943926\n",
      "Epoch 13, loss: 681.351582\n",
      "Epoch 14, loss: 680.736384\n",
      "Epoch 15, loss: 680.157701\n",
      "Epoch 16, loss: 679.596493\n",
      "Epoch 17, loss: 679.023762\n",
      "Epoch 18, loss: 678.467907\n",
      "Epoch 19, loss: 677.922059\n",
      "Epoch 20, loss: 677.402317\n",
      "Epoch 21, loss: 676.894268\n",
      "Epoch 22, loss: 676.374781\n",
      "Epoch 23, loss: 675.867134\n",
      "Epoch 24, loss: 675.383495\n",
      "Epoch 25, loss: 674.884753\n",
      "Epoch 26, loss: 674.423590\n",
      "Epoch 27, loss: 673.953717\n",
      "Epoch 28, loss: 673.487288\n",
      "Epoch 29, loss: 673.039720\n",
      "Epoch 30, loss: 672.607190\n",
      "Epoch 31, loss: 672.182065\n",
      "Epoch 32, loss: 671.734215\n",
      "Epoch 33, loss: 671.333499\n",
      "Epoch 34, loss: 670.898736\n",
      "Epoch 35, loss: 670.505723\n",
      "Epoch 36, loss: 670.101688\n",
      "Epoch 37, loss: 669.714690\n",
      "Epoch 38, loss: 669.332118\n",
      "Epoch 39, loss: 668.952682\n",
      "Epoch 40, loss: 668.578472\n",
      "Epoch 41, loss: 668.219705\n",
      "Epoch 42, loss: 667.848249\n",
      "Epoch 43, loss: 667.496045\n",
      "Epoch 44, loss: 667.141389\n",
      "Epoch 45, loss: 666.801355\n",
      "Epoch 46, loss: 666.470758\n",
      "Epoch 47, loss: 666.109187\n",
      "Epoch 48, loss: 665.825278\n",
      "Epoch 49, loss: 665.486252\n",
      "Epoch 50, loss: 665.170583\n",
      "Epoch 51, loss: 664.850459\n",
      "Epoch 52, loss: 664.548413\n",
      "Epoch 53, loss: 664.243004\n",
      "Epoch 54, loss: 663.936947\n",
      "Epoch 55, loss: 663.650856\n",
      "Epoch 56, loss: 663.377306\n",
      "Epoch 57, loss: 663.092024\n",
      "Epoch 58, loss: 662.799685\n",
      "Epoch 59, loss: 662.538210\n",
      "Epoch 60, loss: 662.258549\n",
      "Epoch 61, loss: 662.002686\n",
      "Epoch 62, loss: 661.731291\n",
      "Epoch 63, loss: 661.474395\n",
      "Epoch 64, loss: 661.227063\n",
      "Epoch 65, loss: 660.993767\n",
      "Epoch 66, loss: 660.725325\n",
      "Epoch 67, loss: 660.482582\n",
      "Epoch 68, loss: 660.251324\n",
      "Epoch 69, loss: 660.011837\n",
      "Epoch 70, loss: 659.783101\n",
      "Epoch 71, loss: 659.561224\n",
      "Epoch 72, loss: 659.315592\n",
      "Epoch 73, loss: 659.097290\n",
      "Epoch 74, loss: 658.866645\n",
      "Epoch 75, loss: 658.667747\n",
      "Epoch 76, loss: 658.456900\n",
      "Epoch 77, loss: 658.230420\n",
      "Epoch 78, loss: 658.035917\n",
      "Epoch 79, loss: 657.832146\n",
      "Epoch 80, loss: 657.619844\n",
      "Epoch 81, loss: 657.415262\n",
      "Epoch 82, loss: 657.235559\n",
      "Epoch 83, loss: 657.043309\n",
      "Epoch 84, loss: 656.852031\n",
      "Epoch 85, loss: 656.671066\n",
      "Epoch 86, loss: 656.482864\n",
      "Epoch 87, loss: 656.301487\n",
      "Epoch 88, loss: 656.121142\n",
      "Epoch 89, loss: 655.945016\n",
      "Epoch 90, loss: 655.758825\n",
      "Epoch 91, loss: 655.588867\n",
      "Epoch 92, loss: 655.419394\n",
      "Epoch 93, loss: 655.241478\n",
      "Epoch 94, loss: 655.070684\n",
      "Epoch 95, loss: 654.910928\n",
      "Epoch 96, loss: 654.749656\n",
      "Epoch 97, loss: 654.594615\n",
      "Epoch 98, loss: 654.428792\n",
      "Epoch 99, loss: 654.282165\n",
      "Epoch 100, loss: 654.121566\n",
      "Epoch 101, loss: 653.962351\n",
      "Epoch 102, loss: 653.826786\n",
      "Epoch 103, loss: 653.671045\n",
      "Epoch 104, loss: 653.524263\n",
      "Epoch 105, loss: 653.366932\n",
      "Epoch 106, loss: 653.231722\n",
      "Epoch 107, loss: 653.082195\n",
      "Epoch 108, loss: 652.952250\n",
      "Epoch 109, loss: 652.794151\n",
      "Epoch 110, loss: 652.663567\n",
      "Epoch 111, loss: 652.518196\n",
      "Epoch 112, loss: 652.402090\n",
      "Epoch 113, loss: 652.261257\n",
      "Epoch 114, loss: 652.129652\n",
      "Epoch 115, loss: 651.998240\n",
      "Epoch 116, loss: 651.886884\n",
      "Epoch 117, loss: 651.741326\n",
      "Epoch 118, loss: 651.623257\n",
      "Epoch 119, loss: 651.498624\n",
      "Epoch 120, loss: 651.368656\n",
      "Epoch 121, loss: 651.248136\n",
      "Epoch 122, loss: 651.137496\n",
      "Epoch 123, loss: 650.998106\n",
      "Epoch 124, loss: 650.882100\n",
      "Epoch 125, loss: 650.764883\n",
      "Epoch 126, loss: 650.658195\n",
      "Epoch 127, loss: 650.551991\n",
      "Epoch 128, loss: 650.414312\n",
      "Epoch 129, loss: 650.312367\n",
      "Epoch 130, loss: 650.226482\n",
      "Epoch 131, loss: 650.103499\n",
      "Epoch 132, loss: 649.983904\n",
      "Epoch 133, loss: 649.875720\n",
      "Epoch 134, loss: 649.773283\n",
      "Epoch 135, loss: 649.674687\n",
      "Epoch 136, loss: 649.560959\n",
      "Epoch 137, loss: 649.460835\n",
      "Epoch 138, loss: 649.370647\n",
      "Epoch 139, loss: 649.235343\n",
      "Epoch 140, loss: 649.144023\n",
      "Epoch 141, loss: 649.047502\n",
      "Epoch 142, loss: 648.933925\n",
      "Epoch 143, loss: 648.837080\n",
      "Epoch 144, loss: 648.752688\n",
      "Epoch 145, loss: 648.660932\n",
      "Epoch 146, loss: 648.557265\n",
      "Epoch 147, loss: 648.461810\n",
      "Epoch 148, loss: 648.369950\n",
      "Epoch 149, loss: 648.262688\n",
      "Epoch 150, loss: 648.186159\n",
      "Epoch 151, loss: 648.082464\n",
      "Epoch 152, loss: 648.003038\n",
      "Epoch 153, loss: 647.899156\n",
      "Epoch 154, loss: 647.821544\n",
      "Epoch 155, loss: 647.720111\n",
      "Epoch 156, loss: 647.629882\n",
      "Epoch 157, loss: 647.549856\n",
      "Epoch 158, loss: 647.467824\n",
      "Epoch 159, loss: 647.378453\n",
      "Epoch 160, loss: 647.290343\n",
      "Epoch 161, loss: 647.183201\n",
      "Epoch 162, loss: 647.120090\n",
      "Epoch 163, loss: 647.036240\n",
      "Epoch 164, loss: 646.946641\n",
      "Epoch 165, loss: 646.870839\n",
      "Epoch 166, loss: 646.792641\n",
      "Epoch 167, loss: 646.707331\n",
      "Epoch 168, loss: 646.618609\n",
      "Epoch 169, loss: 646.544776\n",
      "Epoch 170, loss: 646.470354\n",
      "Epoch 171, loss: 646.390863\n",
      "Epoch 172, loss: 646.322699\n",
      "Epoch 173, loss: 646.236860\n",
      "Epoch 174, loss: 646.153780\n",
      "Epoch 175, loss: 646.077116\n",
      "Epoch 176, loss: 645.993876\n",
      "Epoch 177, loss: 645.920789\n",
      "Epoch 178, loss: 645.854224\n",
      "Epoch 179, loss: 645.777393\n",
      "Epoch 180, loss: 645.707111\n",
      "Epoch 181, loss: 645.645115\n",
      "Epoch 182, loss: 645.563163\n",
      "Epoch 183, loss: 645.499876\n",
      "Epoch 184, loss: 645.416594\n",
      "Epoch 185, loss: 645.339556\n",
      "Epoch 186, loss: 645.274947\n",
      "Epoch 187, loss: 645.222657\n",
      "Epoch 188, loss: 645.143810\n",
      "Epoch 189, loss: 645.060431\n",
      "Epoch 190, loss: 644.987701\n",
      "Epoch 191, loss: 644.919764\n",
      "Epoch 192, loss: 644.867800\n",
      "Epoch 193, loss: 644.783250\n",
      "Epoch 194, loss: 644.725363\n",
      "Epoch 195, loss: 644.676707\n",
      "Epoch 196, loss: 644.583066\n",
      "Epoch 197, loss: 644.516329\n",
      "Epoch 198, loss: 644.468295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199, loss: 644.383084\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "# TODO use validation set to find the best hyperparameters\n",
    "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
    "# than provided initially\n",
    "\n",
    "rez = {}\n",
    "for lr in learning_rates:\n",
    "    for rg in reg_strengths:\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=lr,\n",
    "                       batch_size=batch_size, reg=rg)\n",
    "        pred = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        rez[lr,rg] = accuracy\n",
    "        \n",
    "# print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr, best_rs = [gp for gp, acc in rez.items() if acc==max(rez.values())][0][0],\\\n",
    "                    [gp for gp, acc in rez.items() if acc==max(rez.values())][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 688.252777\n",
      "Epoch 1, loss: 681.831064\n",
      "Epoch 2, loss: 676.264343\n",
      "Epoch 3, loss: 671.914741\n",
      "Epoch 4, loss: 668.227510\n",
      "Epoch 5, loss: 665.143367\n",
      "Epoch 6, loss: 662.236495\n",
      "Epoch 7, loss: 659.769124\n",
      "Epoch 8, loss: 657.846165\n",
      "Epoch 9, loss: 656.285968\n",
      "Epoch 10, loss: 654.718215\n",
      "Epoch 11, loss: 653.199831\n",
      "Epoch 12, loss: 651.818965\n",
      "Epoch 13, loss: 650.913702\n",
      "Epoch 14, loss: 649.802409\n",
      "Epoch 15, loss: 648.988600\n",
      "Epoch 16, loss: 647.983733\n",
      "Epoch 17, loss: 647.262470\n",
      "Epoch 18, loss: 646.534219\n",
      "Epoch 19, loss: 645.913587\n",
      "Epoch 20, loss: 645.184965\n",
      "Epoch 21, loss: 644.379870\n",
      "Epoch 22, loss: 644.025952\n",
      "Epoch 23, loss: 643.326542\n",
      "Epoch 24, loss: 642.950182\n",
      "Epoch 25, loss: 642.409273\n",
      "Epoch 26, loss: 641.869904\n",
      "Epoch 27, loss: 641.314618\n",
      "Epoch 28, loss: 640.928594\n",
      "Epoch 29, loss: 640.329443\n",
      "Epoch 30, loss: 640.204253\n",
      "Epoch 31, loss: 639.719524\n",
      "Epoch 32, loss: 639.237425\n",
      "Epoch 33, loss: 638.968474\n",
      "Epoch 34, loss: 638.508827\n",
      "Epoch 35, loss: 638.377307\n",
      "Epoch 36, loss: 638.055966\n",
      "Epoch 37, loss: 637.763133\n",
      "Epoch 38, loss: 637.216229\n",
      "Epoch 39, loss: 636.874847\n",
      "Epoch 40, loss: 636.568283\n",
      "Epoch 41, loss: 636.357487\n",
      "Epoch 42, loss: 635.979943\n",
      "Epoch 43, loss: 635.896167\n",
      "Epoch 44, loss: 635.602653\n",
      "Epoch 45, loss: 635.236186\n",
      "Epoch 46, loss: 634.964440\n",
      "Epoch 47, loss: 634.916050\n",
      "Epoch 48, loss: 634.535888\n",
      "Epoch 49, loss: 634.257151\n",
      "Epoch 50, loss: 634.223194\n",
      "Epoch 51, loss: 633.933095\n",
      "Epoch 52, loss: 633.650573\n",
      "Epoch 53, loss: 633.507565\n",
      "Epoch 54, loss: 633.105165\n",
      "Epoch 55, loss: 632.862249\n",
      "Epoch 56, loss: 632.489054\n",
      "Epoch 57, loss: 632.613505\n",
      "Epoch 58, loss: 632.382180\n",
      "Epoch 59, loss: 631.942741\n",
      "Epoch 60, loss: 632.032529\n",
      "Epoch 61, loss: 631.825967\n",
      "Epoch 62, loss: 631.585246\n",
      "Epoch 63, loss: 631.194196\n",
      "Epoch 64, loss: 631.188189\n",
      "Epoch 65, loss: 630.928816\n",
      "Epoch 66, loss: 630.897281\n",
      "Epoch 67, loss: 630.700972\n",
      "Epoch 68, loss: 630.635137\n",
      "Epoch 69, loss: 630.212303\n",
      "Epoch 70, loss: 630.222033\n",
      "Epoch 71, loss: 629.940184\n",
      "Epoch 72, loss: 629.693753\n",
      "Epoch 73, loss: 629.663814\n",
      "Epoch 74, loss: 629.581441\n",
      "Epoch 75, loss: 629.288544\n",
      "Epoch 76, loss: 629.188351\n",
      "Epoch 77, loss: 629.089932\n",
      "Epoch 78, loss: 628.684440\n",
      "Epoch 79, loss: 628.758967\n",
      "Epoch 80, loss: 628.532941\n",
      "Epoch 81, loss: 628.330102\n",
      "Epoch 82, loss: 628.269988\n",
      "Epoch 83, loss: 628.117320\n",
      "Epoch 84, loss: 627.880853\n",
      "Epoch 85, loss: 627.827901\n",
      "Epoch 86, loss: 627.610290\n",
      "Epoch 87, loss: 627.485069\n",
      "Epoch 88, loss: 627.350428\n",
      "Epoch 89, loss: 627.296965\n",
      "Epoch 90, loss: 627.162603\n",
      "Epoch 91, loss: 626.950726\n",
      "Epoch 92, loss: 626.875419\n",
      "Epoch 93, loss: 626.752867\n",
      "Epoch 94, loss: 626.624989\n",
      "Epoch 95, loss: 626.432426\n",
      "Epoch 96, loss: 626.312163\n",
      "Epoch 97, loss: 626.406718\n",
      "Epoch 98, loss: 626.253803\n",
      "Epoch 99, loss: 625.959828\n",
      "Epoch 100, loss: 625.852012\n",
      "Epoch 101, loss: 625.949653\n",
      "Epoch 102, loss: 625.516885\n",
      "Epoch 103, loss: 625.460988\n",
      "Epoch 104, loss: 625.487526\n",
      "Epoch 105, loss: 625.304139\n",
      "Epoch 106, loss: 625.092779\n",
      "Epoch 107, loss: 625.104791\n",
      "Epoch 108, loss: 625.141933\n",
      "Epoch 109, loss: 624.904379\n",
      "Epoch 110, loss: 624.732660\n",
      "Epoch 111, loss: 624.575509\n",
      "Epoch 112, loss: 624.444604\n",
      "Epoch 113, loss: 624.461733\n",
      "Epoch 114, loss: 624.205043\n",
      "Epoch 115, loss: 624.310512\n",
      "Epoch 116, loss: 624.113162\n",
      "Epoch 117, loss: 623.934640\n",
      "Epoch 118, loss: 623.922470\n",
      "Epoch 119, loss: 623.786088\n",
      "Epoch 120, loss: 623.739133\n",
      "Epoch 121, loss: 623.584747\n",
      "Epoch 122, loss: 623.697370\n",
      "Epoch 123, loss: 623.505785\n",
      "Epoch 124, loss: 623.448830\n",
      "Epoch 125, loss: 623.196845\n",
      "Epoch 126, loss: 623.003152\n",
      "Epoch 127, loss: 623.144866\n",
      "Epoch 128, loss: 622.885231\n",
      "Epoch 129, loss: 622.758589\n",
      "Epoch 130, loss: 622.592002\n",
      "Epoch 131, loss: 622.658709\n",
      "Epoch 132, loss: 622.561612\n",
      "Epoch 133, loss: 622.333142\n",
      "Epoch 134, loss: 622.448421\n",
      "Epoch 135, loss: 622.137897\n",
      "Epoch 136, loss: 622.294071\n",
      "Epoch 137, loss: 621.854074\n",
      "Epoch 138, loss: 622.088380\n",
      "Epoch 139, loss: 621.823653\n",
      "Epoch 140, loss: 621.779307\n",
      "Epoch 141, loss: 621.731751\n",
      "Epoch 142, loss: 621.769852\n",
      "Epoch 143, loss: 621.614813\n",
      "Epoch 144, loss: 621.377898\n",
      "Epoch 145, loss: 621.580157\n",
      "Epoch 146, loss: 621.163208\n",
      "Epoch 147, loss: 621.134339\n",
      "Epoch 148, loss: 621.041983\n",
      "Epoch 149, loss: 621.146988\n",
      "Epoch 150, loss: 620.880797\n",
      "Epoch 151, loss: 621.095692\n",
      "Epoch 152, loss: 620.717024\n",
      "Epoch 153, loss: 620.678131\n",
      "Epoch 154, loss: 620.349499\n",
      "Epoch 155, loss: 620.607629\n",
      "Epoch 156, loss: 620.308151\n",
      "Epoch 157, loss: 620.411102\n",
      "Epoch 158, loss: 620.353504\n",
      "Epoch 159, loss: 620.226160\n",
      "Epoch 160, loss: 620.136753\n",
      "Epoch 161, loss: 619.995967\n",
      "Epoch 162, loss: 619.942985\n",
      "Epoch 163, loss: 619.899748\n",
      "Epoch 164, loss: 619.796856\n",
      "Epoch 165, loss: 619.692507\n",
      "Epoch 166, loss: 619.593338\n",
      "Epoch 167, loss: 619.666314\n",
      "Epoch 168, loss: 619.489784\n",
      "Epoch 169, loss: 619.265487\n",
      "Epoch 170, loss: 619.266483\n",
      "Epoch 171, loss: 619.278202\n",
      "Epoch 172, loss: 619.367000\n",
      "Epoch 173, loss: 619.233788\n",
      "Epoch 174, loss: 619.202133\n",
      "Epoch 175, loss: 618.996666\n",
      "Epoch 176, loss: 618.866653\n",
      "Epoch 177, loss: 618.904313\n",
      "Epoch 178, loss: 618.698659\n",
      "Epoch 179, loss: 618.811403\n",
      "Epoch 180, loss: 618.560617\n",
      "Epoch 181, loss: 618.465985\n",
      "Epoch 182, loss: 618.475341\n",
      "Epoch 183, loss: 618.458615\n",
      "Epoch 184, loss: 618.155559\n",
      "Epoch 185, loss: 618.156296\n",
      "Epoch 186, loss: 618.149765\n",
      "Epoch 187, loss: 617.963780\n",
      "Epoch 188, loss: 617.888759\n",
      "Epoch 189, loss: 618.007694\n",
      "Epoch 190, loss: 617.948541\n",
      "Epoch 191, loss: 617.683069\n",
      "Epoch 192, loss: 617.796159\n",
      "Epoch 193, loss: 617.635067\n",
      "Epoch 194, loss: 617.585828\n",
      "Epoch 195, loss: 617.637966\n",
      "Epoch 196, loss: 617.471558\n",
      "Epoch 197, loss: 617.384191\n",
      "Epoch 198, loss: 617.365053\n",
      "Epoch 199, loss: 617.308661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[688.2527765913826,\n",
       " 681.8310643475226,\n",
       " 676.2643427412991,\n",
       " 671.9147414691951,\n",
       " 668.2275100743637,\n",
       " 665.1433671931263,\n",
       " 662.236494630657,\n",
       " 659.7691243001384,\n",
       " 657.8461650028083,\n",
       " 656.2859679187364,\n",
       " 654.7182153226719,\n",
       " 653.1998314892285,\n",
       " 651.8189653869514,\n",
       " 650.9137022529011,\n",
       " 649.8024085846841,\n",
       " 648.9886003876903,\n",
       " 647.9837325008367,\n",
       " 647.2624697778563,\n",
       " 646.5342187526719,\n",
       " 645.9135872692207,\n",
       " 645.1849646511672,\n",
       " 644.3798697336003,\n",
       " 644.0259519000371,\n",
       " 643.326541996434,\n",
       " 642.9501820860795,\n",
       " 642.409273495477,\n",
       " 641.869903870963,\n",
       " 641.3146177262636,\n",
       " 640.92859440988,\n",
       " 640.3294431828659,\n",
       " 640.2042531166666,\n",
       " 639.7195235916821,\n",
       " 639.2374250089999,\n",
       " 638.9684742243269,\n",
       " 638.5088271011266,\n",
       " 638.3773068595814,\n",
       " 638.0559658057548,\n",
       " 637.763133174429,\n",
       " 637.2162285170132,\n",
       " 636.8748474140316,\n",
       " 636.5682832441034,\n",
       " 636.3574874920447,\n",
       " 635.9799432918005,\n",
       " 635.8961671379226,\n",
       " 635.6026532713331,\n",
       " 635.2361857282461,\n",
       " 634.9644404596514,\n",
       " 634.9160497552282,\n",
       " 634.5358878098,\n",
       " 634.2571509946214,\n",
       " 634.2231941176235,\n",
       " 633.9330948399751,\n",
       " 633.6505727395762,\n",
       " 633.5075645581422,\n",
       " 633.105164592758,\n",
       " 632.8622488289171,\n",
       " 632.4890540793016,\n",
       " 632.6135046883212,\n",
       " 632.3821798685674,\n",
       " 631.9427410109857,\n",
       " 632.0325294551842,\n",
       " 631.8259671103314,\n",
       " 631.585246483304,\n",
       " 631.1941963768893,\n",
       " 631.1881893876092,\n",
       " 630.928815524692,\n",
       " 630.8972808848666,\n",
       " 630.7009724406697,\n",
       " 630.635136819221,\n",
       " 630.2123031924291,\n",
       " 630.2220333101999,\n",
       " 629.9401842063406,\n",
       " 629.6937528006112,\n",
       " 629.6638135759579,\n",
       " 629.5814413461615,\n",
       " 629.288543756197,\n",
       " 629.1883505999556,\n",
       " 629.0899318336304,\n",
       " 628.6844398772478,\n",
       " 628.758967139471,\n",
       " 628.5329413734482,\n",
       " 628.3301024095165,\n",
       " 628.2699881334835,\n",
       " 628.1173200005567,\n",
       " 627.8808533888034,\n",
       " 627.8279011459055,\n",
       " 627.61028950833,\n",
       " 627.4850694821569,\n",
       " 627.3504278591571,\n",
       " 627.2969646947184,\n",
       " 627.1626029382134,\n",
       " 626.9507264602873,\n",
       " 626.8754186498777,\n",
       " 626.752867021829,\n",
       " 626.6249886358539,\n",
       " 626.4324259882093,\n",
       " 626.312163398359,\n",
       " 626.4067177472753,\n",
       " 626.2538029968671,\n",
       " 625.9598279550609,\n",
       " 625.8520121795657,\n",
       " 625.949653412848,\n",
       " 625.5168849090832,\n",
       " 625.4609875551862,\n",
       " 625.4875257932523,\n",
       " 625.3041393199503,\n",
       " 625.092779351067,\n",
       " 625.1047905974178,\n",
       " 625.1419325591179,\n",
       " 624.9043786469686,\n",
       " 624.7326598000875,\n",
       " 624.5755094546214,\n",
       " 624.444604285773,\n",
       " 624.4617325806996,\n",
       " 624.205042831714,\n",
       " 624.3105123117092,\n",
       " 624.1131617941248,\n",
       " 623.9346396502464,\n",
       " 623.9224695712983,\n",
       " 623.7860883896885,\n",
       " 623.7391333374073,\n",
       " 623.5847468929311,\n",
       " 623.6973701538648,\n",
       " 623.5057850696028,\n",
       " 623.448829582488,\n",
       " 623.1968453110736,\n",
       " 623.0031519521482,\n",
       " 623.1448661220408,\n",
       " 622.8852312060535,\n",
       " 622.7585887110129,\n",
       " 622.5920015278451,\n",
       " 622.6587085070645,\n",
       " 622.5616121522039,\n",
       " 622.3331420916727,\n",
       " 622.448421354527,\n",
       " 622.1378974779603,\n",
       " 622.2940711765775,\n",
       " 621.8540739480515,\n",
       " 622.0883796004549,\n",
       " 621.8236533691995,\n",
       " 621.7793074847084,\n",
       " 621.7317512384022,\n",
       " 621.7698516718788,\n",
       " 621.6148132026776,\n",
       " 621.37789796911,\n",
       " 621.5801571537637,\n",
       " 621.1632081977018,\n",
       " 621.1343393635383,\n",
       " 621.0419827348544,\n",
       " 621.1469875742756,\n",
       " 620.8807972270823,\n",
       " 621.095692213857,\n",
       " 620.7170243579916,\n",
       " 620.6781308827191,\n",
       " 620.3494988406999,\n",
       " 620.607629091733,\n",
       " 620.3081513945965,\n",
       " 620.4111020364094,\n",
       " 620.3535035949337,\n",
       " 620.226160257279,\n",
       " 620.1367534881683,\n",
       " 619.9959672080017,\n",
       " 619.9429846579648,\n",
       " 619.8997478193161,\n",
       " 619.7968564886156,\n",
       " 619.6925067111434,\n",
       " 619.5933384209998,\n",
       " 619.6663136369502,\n",
       " 619.4897838130656,\n",
       " 619.2654865279346,\n",
       " 619.2664830399177,\n",
       " 619.2782018020661,\n",
       " 619.3669998888091,\n",
       " 619.2337876222773,\n",
       " 619.2021333357478,\n",
       " 618.9966661276604,\n",
       " 618.8666532003735,\n",
       " 618.9043133664521,\n",
       " 618.6986585302507,\n",
       " 618.8114027031876,\n",
       " 618.5606170642895,\n",
       " 618.4659846563402,\n",
       " 618.4753413884335,\n",
       " 618.4586147139904,\n",
       " 618.155559454928,\n",
       " 618.1562956112896,\n",
       " 618.1497647488061,\n",
       " 617.96378026076,\n",
       " 617.8887594269072,\n",
       " 618.0076942134293,\n",
       " 617.9485407526968,\n",
       " 617.6830688955022,\n",
       " 617.796158906444,\n",
       " 617.6350666633949,\n",
       " 617.5858275022872,\n",
       " 617.6379658556709,\n",
       " 617.4715579634154,\n",
       " 617.3841912872315,\n",
       " 617.3650534678901,\n",
       " 617.3086611908954]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "best_classifier.fit(train_X, train_y, epochs=num_epochs, learning_rate=best_lr,\n",
    "                       batch_size=batch_size, reg=best_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.211000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
